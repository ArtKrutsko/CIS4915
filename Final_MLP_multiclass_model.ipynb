{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "import ast\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "pd.set_option('display.max_columns', None)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import keras_tuner as kt\n",
    "tf.random.set_seed(50)\n",
    "np.random.seed(50)\n",
    "\n",
    "df = pd.read_csv(\"data/full_set.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to prepare one_hot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_CLASS = \"CHM2210\"\n",
    "\n",
    "# converts strings to arrays\n",
    "df['Classes'] = df['Classes'].apply(ast.literal_eval)\n",
    "df['Semester Grades'] = df['Semester Grades'].apply(ast.literal_eval)\n",
    "df['Semester Points'] = df['Semester Points'].apply(ast.literal_eval)\n",
    "df['CRN'] = df['CRN'].apply(ast.literal_eval)\n",
    "\n",
    "# find all people who took class\n",
    "Pidms_with_TARGET_CLASS = df[df['Classes'].apply(lambda x: TARGET_CLASS in x)]['Pidm'].unique()\n",
    "df = df[df['Pidm'].isin(Pidms_with_TARGET_CLASS)]\n",
    "df = df[['Pidm', 'Semester', 'HS GPA', 'Converted_SAT', 'Semester Points', 'Semester Grades', 'CRN', 'Classes']]\n",
    "df.head(4)\n",
    "\n",
    "# Find the first semester with TARGET_CLASS for each student\n",
    "def find_first_semester(student_df):\n",
    "    chm2210_row = student_df[student_df['Classes'].apply(lambda x: TARGET_CLASS in x)]\n",
    "    if not chm2210_row.empty:\n",
    "        return chm2210_row['Semester'].min()\n",
    "    return None\n",
    "\n",
    "first_semester = df.groupby('Pidm').apply(lambda x: find_first_semester(x)).rename('Target_Semester')\n",
    "df = df.merge(first_semester, on='Pidm')\n",
    "\n",
    "# filter all semesters after student took TARGET_CLASS\n",
    "filtered_df = df[df['Semester'] <= df['Target_Semester']]\n",
    "\n",
    "# find grades/points for TARGET_CLASS and output it to a new column\n",
    "def find_class_grades(student_df):\n",
    "    for _, row in student_df.iterrows():\n",
    "        if TARGET_CLASS in row['Classes']:\n",
    "            index = row['Classes'].index(TARGET_CLASS)\n",
    "            return row['Semester Points'][index], row['Semester Grades'][index]\n",
    "    return None, None\n",
    "\n",
    "class_grades = filtered_df.groupby('Pidm').apply(lambda x: find_class_grades(x)).apply(pd.Series)\n",
    "class_grades.columns = ['Target_Points', 'Target_Grade']\n",
    "\n",
    "final_df = filtered_df.merge(class_grades, on='Pidm')\n",
    "\n",
    "# filter out these grades\n",
    "final_df = final_df[~final_df['Target_Grade'].isin(['WE', 'IF', 'W', 'WC'])]\n",
    "\n",
    "\n",
    "final_df = final_df[final_df['Semester'] < final_df['Target_Semester']]\n",
    "\n",
    "groupped_df = final_df.groupby('Pidm').agg({\n",
    "    \"HS GPA\": 'first',\n",
    "    'Converted_SAT': 'first',\n",
    "    'Semester Grades': lambda x: sum(x, []),\n",
    "    'Semester Points': lambda x: sum(x, []),\n",
    "    'Classes': lambda x: sum(x, []),\n",
    "    'CRN': lambda x: sum(x, []),\n",
    "    'Target_Grade': 'first',\n",
    "    'Target_Points': 'first',\n",
    "}).reset_index()\n",
    "\n",
    "all_classes = sorted(set(chain.from_iterable(groupped_df['Classes'])))\n",
    "\n",
    "def create_one_hot(classes, points, all_classes):\n",
    "    one_hot_vector = [-1] * len(all_classes)\n",
    "    for class_name, point in zip(classes, points):\n",
    "        if class_name in all_classes:\n",
    "            one_hot_vector[all_classes.index(class_name)] = point\n",
    "    return one_hot_vector\n",
    "\n",
    "groupped_df['One_Hot_Classes'] = groupped_df.apply(\n",
    "    lambda row: create_one_hot(row['Classes'], row['Semester Points'], all_classes), axis=1\n",
    ")\n",
    "\n",
    "one_hot_df = pd.DataFrame(groupped_df['One_Hot_Classes'].tolist(), columns=all_classes, index=groupped_df['Pidm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code for models (change non max count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9424, 355) (1178, 355) (1179, 355)\n"
     ]
    }
   ],
   "source": [
    "train, testing_data = train_test_split(one_hot_df, test_size=0.2, random_state=50)\n",
    "dev, test = train_test_split(testing_data, test_size=0.5, random_state=50)\n",
    "\n",
    "train_set = one_hot_df[one_hot_df.index.isin(train.index)]\n",
    "dev_set = one_hot_df[one_hot_df.index.isin(dev.index)]\n",
    "test_set = one_hot_df[one_hot_df.index.isin(test.index)]\n",
    "columns_to_remove = []\n",
    "for column in train_set.columns:\n",
    "    value_counts = train_set[column].value_counts()\n",
    "    max_count = value_counts.max()\n",
    "    non_max_count = value_counts.sum() - max_count\n",
    "    \n",
    "    if non_max_count <= 20:\n",
    "        columns_to_remove.append(column)\n",
    "        \n",
    "train_set = train_set.drop(columns=columns_to_remove)\n",
    "dev_set = dev_set.drop(columns=columns_to_remove)\n",
    "test_set = test_set.drop(columns=columns_to_remove)\n",
    "\n",
    "print(train_set.shape, dev_set.shape, test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pass/fail column\n",
    "def categorize_grade(grade):\n",
    "    fail_grades = ['F', 'IF', 'W', 'D-', 'F', 'D+', 'D#', 'D+', 'F#', 'D', 'D', 'D-', 'U', 'W', \n",
    "                   'F*', 'D*', 'CF', 'I', 'FF', 'Z', 'W*', 'F+', 'F-', 'F#', 'F*', 'D-*', 'IF', \n",
    "                   'IF*', 'D+*', 'CIF', 'Z*', 'IU', 'M', 'CI', 'MU', 'U*', 'ID', 'IB', 'IU*', \n",
    "                   'IS', 'CW']\n",
    "    \n",
    "    # Categorize the grade into one of the four classes\n",
    "    if grade in fail_grades:\n",
    "        return 'Fail'\n",
    "    elif grade.startswith('A'):\n",
    "        return 'A class'\n",
    "    elif grade.startswith('B'):\n",
    "        return 'B class'\n",
    "    elif grade.startswith('C'):\n",
    "        return 'C class'\n",
    "    else:\n",
    "        return 'Fail'  # Default to Fail if grade doesn't match known categories\n",
    "\n",
    "#Add columns fro grouped_df\n",
    "groupped_df_filtered = groupped_df[groupped_df['Pidm'].isin(train_set.index)]\n",
    "add_columns = ['HS GPA', 'Converted_SAT', 'Target_Grade']\n",
    "groupped_df_filtered.set_index('Pidm', inplace=True)\n",
    "train_set = train_set.join(groupped_df_filtered[add_columns], )\n",
    "\n",
    "groupped_df_filtered = groupped_df[groupped_df['Pidm'].isin(dev_set.index)]\n",
    "add_columns = ['HS GPA', 'Converted_SAT', 'Target_Grade']\n",
    "groupped_df_filtered.set_index('Pidm', inplace=True)\n",
    "dev_set = dev_set.join(groupped_df_filtered[add_columns], )\n",
    "\n",
    "# Apply the categorization function\n",
    "train_set['grade_category'] = train_set['Target_Grade'].apply(categorize_grade)\n",
    "dev_set['grade_category'] = dev_set['Target_Grade'].apply(categorize_grade)\n",
    "\n",
    "# Create one-hot encoded columns\n",
    "train_set = pd.get_dummies(train_set, columns=['grade_category'])\n",
    "dev_set = pd.get_dummies(dev_set, columns=['grade_category'])\n",
    "\n",
    "# Ensure that all one-hot encoding columns are present\n",
    "for col in ['grade_category_A class', 'grade_category_B class', 'grade_category_C class', 'grade_category_Fail']:\n",
    "    if col not in train_set:\n",
    "        train_set[col] = 0\n",
    "    if col not in dev_set:\n",
    "        dev_set[col] = 0\n",
    "\n",
    "# # Drop irrelevant columns\n",
    "X = train_set.drop(columns=['grade_category_A class', 'grade_category_B class', 'grade_category_C class', 'grade_category_Fail', 'Target_Grade'])\n",
    "X_dev = dev_set.drop(columns=['grade_category_A class', 'grade_category_B class', 'grade_category_C class', 'grade_category_Fail', 'Target_Grade'])\n",
    "\n",
    "# Drop rows with missing values\n",
    "X = X.dropna()\n",
    "X_dev = X_dev.dropna()\n",
    "X = X.astype('float32')\n",
    "X_dev = X_dev.astype('float32')\n",
    "\n",
    "# Extract the target variable (pass/fail)\n",
    "y = train_set.loc[X.index, ['grade_category_A class', 'grade_category_B class', 'grade_category_C class', 'grade_category_Fail']].values.astype('float32')\n",
    "y_dev = dev_set.loc[X_dev.index, ['grade_category_A class', 'grade_category_B class', 'grade_category_C class', 'grade_category_Fail']].values.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 2.7401 - categorical_accuracy: 0.2933\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.33050, saving model to multiclass_mlp_3l.h5\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 2.7124 - categorical_accuracy: 0.2904 - val_loss: 1.8800 - val_categorical_accuracy: 0.3305\n",
      "Epoch 2/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.7127 - categorical_accuracy: 0.3229\n",
      "Epoch 2: val_categorical_accuracy improved from 0.33050 to 0.36021, saving model to multiclass_mlp_3l.h5\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.7134 - categorical_accuracy: 0.3227 - val_loss: 1.4335 - val_categorical_accuracy: 0.3602\n",
      "Epoch 3/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.6317 - categorical_accuracy: 0.3373\n",
      "Epoch 3: val_categorical_accuracy improved from 0.36021 to 0.41220, saving model to multiclass_mlp_3l.h5\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.6293 - categorical_accuracy: 0.3351 - val_loss: 1.7585 - val_categorical_accuracy: 0.4122\n",
      "Epoch 4/70\n",
      "213/236 [==========================>...] - ETA: 0s - loss: 1.3969 - categorical_accuracy: 0.3593\n",
      "Epoch 4: val_categorical_accuracy did not improve from 0.41220\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.4070 - categorical_accuracy: 0.3536 - val_loss: 1.8029 - val_categorical_accuracy: 0.3119\n",
      "Epoch 5/70\n",
      "210/236 [=========================>....] - ETA: 0s - loss: 1.4832 - categorical_accuracy: 0.3506\n",
      "Epoch 5: val_categorical_accuracy did not improve from 0.41220\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.4663 - categorical_accuracy: 0.3527 - val_loss: 1.7514 - val_categorical_accuracy: 0.3050\n",
      "Epoch 6/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.3503 - categorical_accuracy: 0.3558\n",
      "Epoch 6: val_categorical_accuracy did not improve from 0.41220\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.3503 - categorical_accuracy: 0.3558 - val_loss: 1.3615 - val_categorical_accuracy: 0.3337\n",
      "Epoch 7/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.3401 - categorical_accuracy: 0.3576\n",
      "Epoch 7: val_categorical_accuracy improved from 0.41220 to 0.43077, saving model to multiclass_mlp_3l.h5\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.3401 - categorical_accuracy: 0.3575 - val_loss: 1.2822 - val_categorical_accuracy: 0.4308\n",
      "Epoch 8/70\n",
      "208/236 [=========================>....] - ETA: 0s - loss: 1.3074 - categorical_accuracy: 0.3694\n",
      "Epoch 8: val_categorical_accuracy did not improve from 0.43077\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.3069 - categorical_accuracy: 0.3702 - val_loss: 1.2581 - val_categorical_accuracy: 0.3915\n",
      "Epoch 9/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.3000 - categorical_accuracy: 0.3714\n",
      "Epoch 9: val_categorical_accuracy did not improve from 0.43077\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.3027 - categorical_accuracy: 0.3701 - val_loss: 1.1999 - val_categorical_accuracy: 0.4271\n",
      "Epoch 10/70\n",
      "216/236 [==========================>...] - ETA: 0s - loss: 1.2758 - categorical_accuracy: 0.3806\n",
      "Epoch 10: val_categorical_accuracy did not improve from 0.43077\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.2748 - categorical_accuracy: 0.3821 - val_loss: 1.2306 - val_categorical_accuracy: 0.3761\n",
      "Epoch 11/70\n",
      "212/236 [=========================>....] - ETA: 0s - loss: 1.2549 - categorical_accuracy: 0.3917\n",
      "Epoch 11: val_categorical_accuracy did not improve from 0.43077\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.2585 - categorical_accuracy: 0.3893 - val_loss: 1.2809 - val_categorical_accuracy: 0.3310\n",
      "Epoch 12/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2675 - categorical_accuracy: 0.3825\n",
      "Epoch 12: val_categorical_accuracy did not improve from 0.43077\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.2689 - categorical_accuracy: 0.3819 - val_loss: 1.3431 - val_categorical_accuracy: 0.3093\n",
      "Epoch 13/70\n",
      "204/236 [========================>.....] - ETA: 0s - loss: 1.2609 - categorical_accuracy: 0.3856\n",
      "Epoch 13: val_categorical_accuracy improved from 0.43077 to 0.44138, saving model to multiclass_mlp_3l.h5\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.2582 - categorical_accuracy: 0.3856 - val_loss: 1.1663 - val_categorical_accuracy: 0.4414\n",
      "Epoch 14/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.2627 - categorical_accuracy: 0.3816\n",
      "Epoch 14: val_categorical_accuracy improved from 0.44138 to 0.47639, saving model to multiclass_mlp_3l.h5\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.2627 - categorical_accuracy: 0.3816 - val_loss: 1.1481 - val_categorical_accuracy: 0.4764\n",
      "Epoch 15/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.2566 - categorical_accuracy: 0.3913\n",
      "Epoch 15: val_categorical_accuracy did not improve from 0.47639\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.2551 - categorical_accuracy: 0.3912 - val_loss: 1.2092 - val_categorical_accuracy: 0.4286\n",
      "Epoch 16/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.2530 - categorical_accuracy: 0.3948\n",
      "Epoch 16: val_categorical_accuracy did not improve from 0.47639\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.2527 - categorical_accuracy: 0.3949 - val_loss: 1.1930 - val_categorical_accuracy: 0.4403\n",
      "Epoch 17/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.2428 - categorical_accuracy: 0.4040\n",
      "Epoch 17: val_categorical_accuracy did not improve from 0.47639\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.2453 - categorical_accuracy: 0.4027 - val_loss: 1.3763 - val_categorical_accuracy: 0.2759\n",
      "Epoch 18/70\n",
      "210/236 [=========================>....] - ETA: 0s - loss: 1.2708 - categorical_accuracy: 0.3793\n",
      "Epoch 18: val_categorical_accuracy did not improve from 0.47639\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.2681 - categorical_accuracy: 0.3812 - val_loss: 1.2115 - val_categorical_accuracy: 0.4525\n",
      "Epoch 19/70\n",
      "206/236 [=========================>....] - ETA: 0s - loss: 1.2519 - categorical_accuracy: 0.3920\n",
      "Epoch 19: val_categorical_accuracy did not improve from 0.47639\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.2489 - categorical_accuracy: 0.3949 - val_loss: 1.1504 - val_categorical_accuracy: 0.4456\n",
      "Epoch 20/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.2332 - categorical_accuracy: 0.4128\n",
      "Epoch 20: val_categorical_accuracy did not improve from 0.47639\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.2323 - categorical_accuracy: 0.4141 - val_loss: 1.1527 - val_categorical_accuracy: 0.4679\n",
      "Epoch 21/70\n",
      "208/236 [=========================>....] - ETA: 0s - loss: 1.2270 - categorical_accuracy: 0.4105\n",
      "Epoch 21: val_categorical_accuracy did not improve from 0.47639\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.2245 - categorical_accuracy: 0.4131 - val_loss: 1.1588 - val_categorical_accuracy: 0.4690\n",
      "Epoch 22/70\n",
      "213/236 [==========================>...] - ETA: 0s - loss: 1.2307 - categorical_accuracy: 0.4124\n",
      "Epoch 22: val_categorical_accuracy did not improve from 0.47639\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.2330 - categorical_accuracy: 0.4124 - val_loss: 1.1886 - val_categorical_accuracy: 0.4286\n",
      "Epoch 23/70\n",
      "231/236 [============================>.] - ETA: 0s - loss: 1.2281 - categorical_accuracy: 0.4113\n",
      "Epoch 23: val_categorical_accuracy did not improve from 0.47639\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.2273 - categorical_accuracy: 0.4116 - val_loss: 1.1459 - val_categorical_accuracy: 0.4727\n",
      "Epoch 24/70\n",
      "215/236 [==========================>...] - ETA: 0s - loss: 1.2183 - categorical_accuracy: 0.4172\n",
      "Epoch 24: val_categorical_accuracy did not improve from 0.47639\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.2212 - categorical_accuracy: 0.4164 - val_loss: 1.2558 - val_categorical_accuracy: 0.3857\n",
      "Epoch 25/70\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.2202 - categorical_accuracy: 0.4113\n",
      "Epoch 25: val_categorical_accuracy did not improve from 0.47639\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.2223 - categorical_accuracy: 0.4099 - val_loss: 1.3477 - val_categorical_accuracy: 0.3151\n",
      "Epoch 26/70\n",
      "211/236 [=========================>....] - ETA: 0s - loss: 1.2371 - categorical_accuracy: 0.4025\n",
      "Epoch 26: val_categorical_accuracy did not improve from 0.47639\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.2406 - categorical_accuracy: 0.3987 - val_loss: 1.1519 - val_categorical_accuracy: 0.4605\n",
      "Epoch 27/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.2092 - categorical_accuracy: 0.4280\n",
      "Epoch 27: val_categorical_accuracy did not improve from 0.47639\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.2104 - categorical_accuracy: 0.4263 - val_loss: 1.2662 - val_categorical_accuracy: 0.3920\n",
      "Epoch 28/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1920 - categorical_accuracy: 0.4380\n",
      "Epoch 28: val_categorical_accuracy did not improve from 0.47639\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1924 - categorical_accuracy: 0.4376 - val_loss: 1.1922 - val_categorical_accuracy: 0.4393\n",
      "Epoch 29/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.1865 - categorical_accuracy: 0.4407\n",
      "Epoch 29: val_categorical_accuracy did not improve from 0.47639\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1890 - categorical_accuracy: 0.4393 - val_loss: 1.2040 - val_categorical_accuracy: 0.4228\n",
      "Epoch 30/70\n",
      "215/236 [==========================>...] - ETA: 0s - loss: 1.1836 - categorical_accuracy: 0.4452\n",
      "Epoch 30: val_categorical_accuracy did not improve from 0.47639\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1815 - categorical_accuracy: 0.4461 - val_loss: 1.2095 - val_categorical_accuracy: 0.4212\n",
      "Epoch 31/70\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.1836 - categorical_accuracy: 0.4422\n",
      "Epoch 31: val_categorical_accuracy improved from 0.47639 to 0.48329, saving model to multiclass_mlp_3l.h5\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1840 - categorical_accuracy: 0.4418 - val_loss: 1.1359 - val_categorical_accuracy: 0.4833\n",
      "Epoch 32/70\n",
      "205/236 [=========================>....] - ETA: 0s - loss: 1.1972 - categorical_accuracy: 0.4383\n",
      "Epoch 32: val_categorical_accuracy improved from 0.48329 to 0.49655, saving model to multiclass_mlp_3l.h5\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1961 - categorical_accuracy: 0.4369 - val_loss: 1.1099 - val_categorical_accuracy: 0.4966\n",
      "Epoch 33/70\n",
      "215/236 [==========================>...] - ETA: 0s - loss: 1.1791 - categorical_accuracy: 0.4442\n",
      "Epoch 33: val_categorical_accuracy did not improve from 0.49655\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.1815 - categorical_accuracy: 0.4430 - val_loss: 1.2305 - val_categorical_accuracy: 0.4011\n",
      "Epoch 34/70\n",
      "236/236 [==============================] - ETA: 0s - loss: 1.1736 - categorical_accuracy: 0.4524\n",
      "Epoch 34: val_categorical_accuracy did not improve from 0.49655\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1736 - categorical_accuracy: 0.4524 - val_loss: 1.1139 - val_categorical_accuracy: 0.4907\n",
      "Epoch 35/70\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 1.1921 - categorical_accuracy: 0.4398\n",
      "Epoch 35: val_categorical_accuracy improved from 0.49655 to 0.50027, saving model to multiclass_mlp_3l.h5\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1911 - categorical_accuracy: 0.4393 - val_loss: 1.0967 - val_categorical_accuracy: 0.5003\n",
      "Epoch 36/70\n",
      "205/236 [=========================>....] - ETA: 0s - loss: 1.1613 - categorical_accuracy: 0.4540\n",
      "Epoch 36: val_categorical_accuracy did not improve from 0.50027\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1629 - categorical_accuracy: 0.4534 - val_loss: 1.1535 - val_categorical_accuracy: 0.4801\n",
      "Epoch 37/70\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.1707 - categorical_accuracy: 0.4485\n",
      "Epoch 37: val_categorical_accuracy improved from 0.50027 to 0.51247, saving model to multiclass_mlp_3l.h5\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1716 - categorical_accuracy: 0.4478 - val_loss: 1.0803 - val_categorical_accuracy: 0.5125\n",
      "Epoch 38/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1513 - categorical_accuracy: 0.4553\n",
      "Epoch 38: val_categorical_accuracy did not improve from 0.51247\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1541 - categorical_accuracy: 0.4547 - val_loss: 1.1814 - val_categorical_accuracy: 0.4493\n",
      "Epoch 39/70\n",
      "216/236 [==========================>...] - ETA: 0s - loss: 1.1535 - categorical_accuracy: 0.4569\n",
      "Epoch 39: val_categorical_accuracy improved from 0.51247 to 0.52361, saving model to multiclass_mlp_3l.h5\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1482 - categorical_accuracy: 0.4620 - val_loss: 1.0603 - val_categorical_accuracy: 0.5236\n",
      "Epoch 40/70\n",
      "210/236 [=========================>....] - ETA: 0s - loss: 1.1634 - categorical_accuracy: 0.4491\n",
      "Epoch 40: val_categorical_accuracy did not improve from 0.52361\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.1610 - categorical_accuracy: 0.4520 - val_loss: 1.0592 - val_categorical_accuracy: 0.5210\n",
      "Epoch 41/70\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 1.1364 - categorical_accuracy: 0.4628\n",
      "Epoch 41: val_categorical_accuracy did not improve from 0.52361\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1397 - categorical_accuracy: 0.4615 - val_loss: 1.2003 - val_categorical_accuracy: 0.4249\n",
      "Epoch 42/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.1432 - categorical_accuracy: 0.4556\n",
      "Epoch 42: val_categorical_accuracy did not improve from 0.52361\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1441 - categorical_accuracy: 0.4567 - val_loss: 1.1989 - val_categorical_accuracy: 0.4334\n",
      "Epoch 43/70\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.1484 - categorical_accuracy: 0.4618\n",
      "Epoch 43: val_categorical_accuracy did not improve from 0.52361\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1450 - categorical_accuracy: 0.4656 - val_loss: 1.1785 - val_categorical_accuracy: 0.4531\n",
      "Epoch 44/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.1266 - categorical_accuracy: 0.4706\n",
      "Epoch 44: val_categorical_accuracy did not improve from 0.52361\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1288 - categorical_accuracy: 0.4693 - val_loss: 1.1074 - val_categorical_accuracy: 0.4939\n",
      "Epoch 45/70\n",
      "199/236 [========================>.....] - ETA: 0s - loss: 1.1302 - categorical_accuracy: 0.4648\n",
      "Epoch 45: val_categorical_accuracy did not improve from 0.52361\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1314 - categorical_accuracy: 0.4672 - val_loss: 1.2148 - val_categorical_accuracy: 0.4223\n",
      "Epoch 46/70\n",
      "211/236 [=========================>....] - ETA: 0s - loss: 1.1435 - categorical_accuracy: 0.4559\n",
      "Epoch 46: val_categorical_accuracy did not improve from 0.52361\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1417 - categorical_accuracy: 0.4603 - val_loss: 1.0633 - val_categorical_accuracy: 0.5188\n",
      "Epoch 47/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.1343 - categorical_accuracy: 0.4666\n",
      "Epoch 47: val_categorical_accuracy did not improve from 0.52361\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1326 - categorical_accuracy: 0.4668 - val_loss: 1.1914 - val_categorical_accuracy: 0.4515\n",
      "Epoch 48/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1383 - categorical_accuracy: 0.4663\n",
      "Epoch 48: val_categorical_accuracy improved from 0.52361 to 0.53210, saving model to multiclass_mlp_3l.h5\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1393 - categorical_accuracy: 0.4658 - val_loss: 1.0511 - val_categorical_accuracy: 0.5321\n",
      "Epoch 49/70\n",
      "205/236 [=========================>....] - ETA: 0s - loss: 1.1455 - categorical_accuracy: 0.4569\n",
      "Epoch 49: val_categorical_accuracy did not improve from 0.53210\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1387 - categorical_accuracy: 0.4597 - val_loss: 1.0578 - val_categorical_accuracy: 0.5289\n",
      "Epoch 50/70\n",
      "212/236 [=========================>....] - ETA: 0s - loss: 1.1260 - categorical_accuracy: 0.4730\n",
      "Epoch 50: val_categorical_accuracy did not improve from 0.53210\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1272 - categorical_accuracy: 0.4713 - val_loss: 1.0804 - val_categorical_accuracy: 0.5119\n",
      "Epoch 51/70\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.1289 - categorical_accuracy: 0.4709\n",
      "Epoch 51: val_categorical_accuracy did not improve from 0.53210\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1291 - categorical_accuracy: 0.4698 - val_loss: 1.0618 - val_categorical_accuracy: 0.5156\n",
      "Epoch 52/70\n",
      "206/236 [=========================>....] - ETA: 0s - loss: 1.1218 - categorical_accuracy: 0.4644\n",
      "Epoch 52: val_categorical_accuracy did not improve from 0.53210\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1247 - categorical_accuracy: 0.4643 - val_loss: 1.0470 - val_categorical_accuracy: 0.5241\n",
      "Epoch 53/70\n",
      "216/236 [==========================>...] - ETA: 0s - loss: 1.1195 - categorical_accuracy: 0.4738\n",
      "Epoch 53: val_categorical_accuracy did not improve from 0.53210\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1244 - categorical_accuracy: 0.4715 - val_loss: 1.0458 - val_categorical_accuracy: 0.5241\n",
      "Epoch 54/70\n",
      "214/236 [==========================>...] - ETA: 0s - loss: 1.1162 - categorical_accuracy: 0.4809\n",
      "Epoch 54: val_categorical_accuracy did not improve from 0.53210\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1180 - categorical_accuracy: 0.4811 - val_loss: 1.1612 - val_categorical_accuracy: 0.4578\n",
      "Epoch 55/70\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1214 - categorical_accuracy: 0.4740\n",
      "Epoch 55: val_categorical_accuracy did not improve from 0.53210\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1199 - categorical_accuracy: 0.4754 - val_loss: 1.0432 - val_categorical_accuracy: 0.5289\n",
      "Epoch 56/70\n",
      "216/236 [==========================>...] - ETA: 0s - loss: 1.1231 - categorical_accuracy: 0.4670\n",
      "Epoch 56: val_categorical_accuracy did not improve from 0.53210\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1243 - categorical_accuracy: 0.4682 - val_loss: 1.0483 - val_categorical_accuracy: 0.5273\n",
      "Epoch 57/70\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 1.1226 - categorical_accuracy: 0.4708\n",
      "Epoch 57: val_categorical_accuracy improved from 0.53210 to 0.53316, saving model to multiclass_mlp_3l.h5\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1258 - categorical_accuracy: 0.4678 - val_loss: 1.0457 - val_categorical_accuracy: 0.5332\n",
      "Epoch 58/70\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 1.1233 - categorical_accuracy: 0.4709\n",
      "Epoch 58: val_categorical_accuracy did not improve from 0.53316\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1273 - categorical_accuracy: 0.4712 - val_loss: 1.0942 - val_categorical_accuracy: 0.4854\n",
      "Epoch 59/70\n",
      "207/236 [=========================>....] - ETA: 0s - loss: 1.1335 - categorical_accuracy: 0.4669\n",
      "Epoch 59: val_categorical_accuracy did not improve from 0.53316\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1319 - categorical_accuracy: 0.4668 - val_loss: 1.0968 - val_categorical_accuracy: 0.4950\n",
      "Epoch 60/70\n",
      "212/236 [=========================>....] - ETA: 0s - loss: 1.1149 - categorical_accuracy: 0.4721\n",
      "Epoch 60: val_categorical_accuracy did not improve from 0.53316\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1143 - categorical_accuracy: 0.4725 - val_loss: 1.1245 - val_categorical_accuracy: 0.4870\n",
      "Epoch 61/70\n",
      "207/236 [=========================>....] - ETA: 0s - loss: 1.1074 - categorical_accuracy: 0.4758\n",
      "Epoch 61: val_categorical_accuracy did not improve from 0.53316\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1076 - categorical_accuracy: 0.4763 - val_loss: 1.0659 - val_categorical_accuracy: 0.5268\n",
      "Epoch 62/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.1141 - categorical_accuracy: 0.4776\n",
      "Epoch 62: val_categorical_accuracy did not improve from 0.53316\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1130 - categorical_accuracy: 0.4779 - val_loss: 1.1280 - val_categorical_accuracy: 0.4775\n",
      "Epoch 63/70\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.1098 - categorical_accuracy: 0.4819\n",
      "Epoch 63: val_categorical_accuracy did not improve from 0.53316\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.1081 - categorical_accuracy: 0.4839 - val_loss: 1.1466 - val_categorical_accuracy: 0.4743\n",
      "Epoch 64/70\n",
      "233/236 [============================>.] - ETA: 0s - loss: 1.1034 - categorical_accuracy: 0.4763\n",
      "Epoch 64: val_categorical_accuracy improved from 0.53316 to 0.53793, saving model to multiclass_mlp_3l.h5\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1040 - categorical_accuracy: 0.4759 - val_loss: 1.0454 - val_categorical_accuracy: 0.5379\n",
      "Epoch 65/70\n",
      "213/236 [==========================>...] - ETA: 0s - loss: 1.0967 - categorical_accuracy: 0.4853\n",
      "Epoch 65: val_categorical_accuracy did not improve from 0.53793\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 1.0985 - categorical_accuracy: 0.4856 - val_loss: 1.1077 - val_categorical_accuracy: 0.4812\n",
      "Epoch 66/70\n",
      "215/236 [==========================>...] - ETA: 0s - loss: 1.1034 - categorical_accuracy: 0.4887\n",
      "Epoch 66: val_categorical_accuracy did not improve from 0.53793\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1081 - categorical_accuracy: 0.4869 - val_loss: 1.1502 - val_categorical_accuracy: 0.4541\n",
      "Epoch 67/70\n",
      "215/236 [==========================>...] - ETA: 0s - loss: 1.1057 - categorical_accuracy: 0.4810\n",
      "Epoch 67: val_categorical_accuracy did not improve from 0.53793\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1075 - categorical_accuracy: 0.4815 - val_loss: 1.0460 - val_categorical_accuracy: 0.5369\n",
      "Epoch 68/70\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 1.1080 - categorical_accuracy: 0.4775\n",
      "Epoch 68: val_categorical_accuracy did not improve from 0.53793\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1069 - categorical_accuracy: 0.4767 - val_loss: 1.0640 - val_categorical_accuracy: 0.5231\n",
      "Epoch 69/70\n",
      "210/236 [=========================>....] - ETA: 0s - loss: 1.1030 - categorical_accuracy: 0.4807\n",
      "Epoch 69: val_categorical_accuracy did not improve from 0.53793\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1029 - categorical_accuracy: 0.4831 - val_loss: 1.0392 - val_categorical_accuracy: 0.5279\n",
      "Epoch 70/70\n",
      "215/236 [==========================>...] - ETA: 0s - loss: 1.1120 - categorical_accuracy: 0.4805\n",
      "Epoch 70: val_categorical_accuracy did not improve from 0.53793\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 1.1106 - categorical_accuracy: 0.4819 - val_loss: 1.1110 - val_categorical_accuracy: 0.4775\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(357,)),  # Input layer\n",
    "    tf.keras.layers.Dense(128, activation='relu'),  # Hidden layer 1\n",
    "    tf.keras.layers.Dense(128, activation='relu'),  # Hidden layer 2\n",
    "    tf.keras.layers.Dense(128, activation='relu'),  # Hidden layer 2\n",
    "    tf.keras.layers.Dense(4, activation='softmax')  # Output layer for 4-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('multiclass_mlp_3l.h5', \n",
    "                             monitor='val_categorical_accuracy',  # Monitor validation accuracy\n",
    "                             save_best_only=True, \n",
    "                             mode='max', \n",
    "                             verbose=2)\n",
    "\n",
    "# Train the model with the checkpoint callback\n",
    "history = model.fit(X, y, \n",
    "                    validation_split=0.2,\n",
    "                    epochs=70, \n",
    "                    batch_size=32, \n",
    "                    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0974 - categorical_accuracy: 0.4932\n",
      "Loss: 1.0974, Accuracy: 0.4932\n",
      "37/37 [==============================] - 0s 904us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     A class       0.64      0.75      0.69       399\n",
      "     B class       0.41      0.38      0.39       347\n",
      "     C class       0.38      0.39      0.39       278\n",
      "        Fail       0.39      0.29      0.33       154\n",
      "\n",
      "    accuracy                           0.49      1178\n",
      "   macro avg       0.46      0.45      0.45      1178\n",
      "weighted avg       0.48      0.49      0.48      1178\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1caf48ed420>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGwCAYAAAB7MGXBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABeOklEQVR4nO3dd1gUV9sG8HtpCywLSAdFBCk2bNj1ixoLomLvxhLRxAIG0WCMUTGJNbFigobYYtRobDFqLLHFXlDswYYKEQQRWUDawnx/8LrJCipIGZa9f7nmet05Z2afnVeXh+ecMyMRBEEAERERkUh0xA6AiIiItBuTESIiIhIVkxEiIiISFZMRIiIiEhWTESIiIhIVkxEiIiISFZMRIiIiEpWe2AFUZnl5eXj8+DHkcjkkEonY4RARUTEIgoDU1FQ4ODhAR6fsfnfPzMxEdnZ2qZzLwMAAhoaGpXKu8sRkpAw9fvwYjo6OYodBREQlEBMTg2rVqpXJuTMzM2EktwSUL0rlfHZ2doiOjta4hITJSBmSy+UAAIM6IyDRNRA5Gu1wYONMsUPQOvbmmvWlp+nMZfwuKS+pCgVcnR1V3+VlITs7G1C+gLTOCKCkPydysxF/cz2ys7OZjNC/Xg7NSHQNmIyUExO5qdghaB25qWZ96Wk6UyYj5a5chtn1DEv8c0KQaO40UCYjREREYpMAKGnSo8FTE5mMEBERiU2ik7+V9BwaSnMjJyIiokqBlREiIiKxSSSlMEyjueM0TEaIiIjExmEaIiIiIvGwMkJERCQ2DtMQERGRuEphmEaDBzs0N3IiIiKqFFgZISIiEhuHaYiIiEhUXE1DREREJB5WRoiIiMTGYRoiIiISlZYP0zAZISIiEpuWV0Y0N40iIiKiSoGVESIiIrFxmIaIiIhEJZGUQjLCYRoiIiKid8LKCBERkdh0JPlbSc+hoZiMEBERiU3L54xobuRERERUKbAyQkREJDYtv88IkxEiIiKxcZiGiIiISDysjBAREYmNwzREREQkKi0fpmEyQkREJDYtr4xobhpFRERElQIrI0RERGLjMA0RERGJisM0REREROJhZYSIiEh0pTBMo8H1BSYjREREYuMwDREREZF4WBkhIiISm0RSCqtpNLcywmSEiIhIbFq+tFdzIyciIqJKgZURLTFpZGd0b98Abk62yMzKwfmr9xGy4jfcfZig6mNtIUdIQE+0b14bZnIjnL58F1O/+RX3YxJVfWws5fhyYm+0a14LJsZS3H2YgMVrD2D3kUgRPpXmSUxKQdhPB3D2UhSyspVwdLDCZ/59UKtmVQDAi4wsrNxwACfO30RK6gvYW1dBv+4t0btLC5Ej1zzfb/wTB/66hvuPEmAo1UfjujUw9ePucKluo+qT+CwVC1ftwYmLUVCkZaBZfRfM+qQPnKtZixh55bR47QF89f3vGDuoHeZN7id2OBUPJ7BWLseOHYNEIsHz58/FDqVCadXYFT/++hc6j/oWffxXQE9XFztC/WFsaKDq8/M3H6GGgxWGTlmFth/MR2zcM+z6LkCtz8rZI+DqZIMhQavQevBc/H40EmvmjoKnezUxPpZGUaRlYNy0VdDT08G3M0bi59BA+H/oA7mxoapP6Jq9OHf5NmYEDsDG0EkY0KM1lobvwYlzN0WMXDOdj7yHYb1aY/v3n+Cnbz+GMjcPwz9dhRcZWQAAQRAw9os1eBSXhFVzRmFP+GRUtauCYZNXqvpQ6bh04yHW7zqNum5VxQ6l4no5TFPSTUNViMhPnz4NXV1ddOnSRexQKq3+E7/H5j3n8Pf9eFy/8w8mfPkzHO0t0LC2IwCgZnUbNKvvjMkLfsHlm49w92ECJi/YApmRFH29vVTnaerpjPAtx3Hp5kM8/CcJi9YcQEpqBhrUchTro2mMjTuOw8bKDJ8H9EMdd0fY21RBk/quqGpvqepzPeoRfNo3RuN6LrC3qYKenZuhZg07/H3vHxEj10zrvvkY/Xyawd3ZDrVdq2LhZ4Pw+Ekyrt+OBQBExybi8s2H+GpSPzSoVR0u1W3wZWA/vMjIwu+HL4scfeWR9iILH81ch2WfD4a53EjscCqul5WRkm4aqkIkI2vWrEFAQABOnjyJR48eiR2OVjA1yf9tPFnxAgAg1c8fscvMUqr65OUJyFYq0aJhTdW+s1fuoXcnL5ibGkMikaBPJy8YGOjhZMSdcoxeM526cAu1XKvhi4Wb0H3EHHwYFIrdBy+o9alfuwZOXriFxKQUCIKAS9fuIebxUzRr6CZS1JVHaloGAMBMbgwAyM7J/7suNfh3tFpXVwf6erq4eC26/AOspD5duAWdW9dDu+a1xA6FKjDRk5H09HRs3boV48aNQ/fu3bFu3bq3HpOVlYXg4GA4OjpCKpXCzc0Nq1evLrRvUlISBg8ejGrVqsHY2Bienp7YvHmzWp9t27bB09MTRkZGsLS0RMeOHZGeng4gf9inWbNmkMlkMDc3R+vWrfHw4cPXxqVQKNS2imrOpL44c/kubt2LAwDcfhCPR4+TMHNCD5jJjaCvp4vAEZ1gZ2UGW0sz1XF+09ZAV08H0YcX4snppVjy+SAM+zQcD/55KtZH0RiPnyRj1/5zcHSwxOJZH6KndzMsXf07/jh6SdUncHR31Khmg96jF6Bd/xmY/OU6TP64JxrUqSFe4JWAIAiY8/1uNPF0hoeLPQCgZnVbVLWtgm/C9yIl9QWyc5QI23gYic9SkfCs4v7b1STbD17Elb9jMHNCD7FDqfi0fJhG9AmsW7ZsgYeHBzw8PPDBBx8gICAAM2bMgOQN5abhw4fjzJkzWL58ORo0aIDo6Gg8fVr4D8PMzEx4eXlh6tSpMDU1xd69ezFs2DC4uLigefPmiIuLw+DBg7Fw4UL07t0bqampOHHiBARBgFKpRK9evTBmzBhs3rwZ2dnZOH/+/GtjmzdvHmbPnl0q16UsfRM8AHVdHeAzZolqnzI3D8On/ojQGUPx4Mg3UCpzcexCFA6duqF27PRxvjCXG6Pn+OV49jwdXdvWx7r5o9B1zFLcvPe4vD+KRskTBNSqWRUff+ANAHB3ccCDmATs2n8OPu0bAwB+3XsGN27HYP7nw2BnbY4rNx9g0arfYFlFjqYNXMUMX6PNWrYDf997jK2hAap9+nq6+P7Lkfhs4RY08v0Cujo6aO3lhrb8Db5UxMYnY9qi7dgeOgGGUn2xw6n4tHwCq+jJyOrVq/HBBx8AALp06YK0tDQcPnwYHTt2LLT/7du3sXXrVhw6dEjVx8XF5bXnr1q1KqZMmaJ6HRAQgP379+PXX39VJSNKpRJ9+vSBk5MTAMDT0xMA8OzZM6SkpKB79+6oWTN/qKJ27dqvfa9p06YhKChI9VqhUMDRsWLNpVgwpT983vNE14+W4nHCc7W2K3/H4L2h82EqM4S+vh6Snqfh0NopiLyVP3RWo6oVPhrYFi0Hfo2/78cDAK7f+QctG9XE6P7vIWj+L+X9cTSKZRU5ajjaqO1zqmaNY2fyE76srBz8sPEg5k4dilZN8n8gutawx53oOGz+7QSTkXcUsmwHDp+6gV+WT4C9jblam6eHI/aungJFWgZylLmwNDdB73FL4elRsf7daqIrfz9C4rNUtB++ULUvNzcPpy/fQ/ivf+HJqaXQ1dXc3+SpdImajERFReH8+fPYsWNHfjB6ehg4cCDWrFnz2mQkMjISurq6aNu2bZHeIzc3F/Pnz8eWLVvwzz//ICsrC1lZWZDJZACABg0aoEOHDvD09IS3tzc6d+6Mfv36oUqVKrCwsMDIkSPh7e2NTp06oWPHjhgwYADs7e0LfS+pVAqpVPoOV6J8LPy0P7q1awDfscvw6HHSa/sp0jMBAC6O1mhUuzrmrtwDAKpVNXl5glr/3FwBEh3NzcjLi2et6nj0T6LavpjHSbCzNgcAKHNzoVTmFqi86ehIILxyzentBEFAyLIdOHjyGjYtnQDH/0wUfpWpSf7EyujYRFyLikHQKJ/yCrPSeq+pB05t/lxtn/+XP8Othi0+Gd6JicgrJBLJG0cEiniS0glGBKL+bVi9ejWUSiWqVq0KPT096OnpISwsDDt27EBycnKhxxgZFW829qJFi7BkyRIEBwfjyJEjiIyMhLe3N7KzswEAurq6OHToEP744w/UqVMHoaGh8PDwQHR0/gS2tWvX4syZM2jVqhW2bNkCd3d3nD17tmQfXATfTh2AAT5NMWbGOqS9yISNpRw2lnK18mnPDo3QurEbnKpawuc9T+xc4Y+9x6/i6Lm/AeTPK7n3KAFLpg1G4zpOqFHVChOGvo/2zT2w79gVsT6axhjo2wY3bsfgp23HEBuXhIN/RWL3wfPo45N/DxGZsSEa1nXG9+v/wKXr9/H4yTPsOxKB/ccu470WdUSOXvPMXLoduw5FYOkXH8DESIrEJAUSkxTIzMpW9dl3LBJnL9/Fo8dJOHTyOoZPXolOberh/5p6iBh55SCXGaKOq4PaZmxkAAszGeq4OogdXoXzMhkp6aapJIIgiPIrl1KpRLVq1RAcHIzOnTurtfXt2xcBAQHw9/cvcNyDBw/g4uKCgwcPFlo9OXbsGNq3b4/k5GSYm5vD19cXNjY2qgmueXl5qF27NmrXro1du3YVOD43NxdOTk4ICgpSG3J5qWXLlmjatCmWL1/+1s+oUChgZmYGqecYSHQN3tq/LCVfWFHo/vGzN2DznnMAgI8GtsXEYR1hbSHHk6cK/LLvHL75cT9ylLmq/i6O1pjl3xMtGrhAZixFdEwiVvx8GFv+uFDo+cvbyZ1zxQ7hjU5d+Burfj6A2Lgk2NtUwcAebdCjc1NVe1JyKlb9fADnI+9CkfYCdtbm6NGpGQb2aF1hv2gcqhi+vZMIXNoV/PcLAAunDkI/n2YAgHXb/0L4L8fwNDkV1pam6NO5CfyHd4KBvugj2K9VRSbud0lJdP94KTzdq2nMTc8UCgVsLc2QkpICU1PTMnsPMzMzGPX4DhL9ki19FnIykLF7QpnGW1ZE+xe3Z88eJCcnw8/PD2ZmZmpt/fr1w+rVqwtNRmrUqIERI0Zg1KhRqgmsDx8+REJCAgYMGFCgv6urK7Zv347Tp0+jSpUqWLx4MeLj41VzP86dO4fDhw+jc+fOsLGxwblz55CYmIjatWsjOjoaP/zwA3r06AEHBwdERUXh9u3bGD58eNlclDJUpWnBa/mqH7Ycxw9bjr+xz/2YRIyY+mNphaV1WjethdZNXz9B0rKKHJ8HaMYXdUV3/9jit/YZ2fc9jOz7XjlEQwCwZ1Wg2CFUXJL/bSU9h4YSbZhm9erV6NixY4FEBMivjERGRuLSpUuFHAmEhYWhX79+GD9+PGrVqoUxY8aoluK+asaMGWjcuDG8vb3Rrl072NnZoVevXqp2U1NT/PXXX+jatSvc3d3xxRdfYNGiRfDx8YGxsTH+/vtv9O3bF+7u7vjoo4/g7++Pjz/+uFSuAREREcBhGtGGabRBRRqm0RYVfZimMqqowzSVlSYP02ia8hymMe71fakM07zYNZ7DNERERFR82r6ahskIERGRyJiMEBERkai0PRnhXWeIiIi0zLx589C0aVPI5XLY2NigV69eiIqKUuszcuTIAhNkW7RoodYnKysLAQEBsLKygkwmQ48ePRAbG1vseJiMEBERiU1SSlsRHT9+HBMmTMDZs2dx6NAhKJVKdO7cucDK1C5duiAuLk617du3T609MDAQO3fuxC+//IKTJ08iLS0N3bt3R25uLoqDwzREREQiK81hmlefGF/Yo0r279+v9nrt2rWwsbFBREQE3nvvPbVj7ezsCn27lJQUrF69Ghs2bFDdhPTnn3+Go6Mj/vzzT3h7exc5dFZGiIiIKhFHR0eYmZmptnnz5r31mJSUFACAhYWF2v5jx47BxsYG7u7uGDNmDBISElRtERERyMnJUbuLuoODA+rVq4fTp08XK2ZWRoiIiEQmkaAUKiP5/xMTE6N2n5G3PcBVEAQEBQWhTZs2qFevnmq/j48P+vfvDycnJ0RHR2PGjBl4//33ERERAalUivj4eBgYGKBKlSpq57O1tUV8fHyxQmcyQkREJDIJSuMOqvnHm5qaFuumZ/7+/rh69SpOnjyptn/gwIGqP9erVw9NmjSBk5MT9u7diz59+rz2fIIgFPuzcJiGiIhISwUEBGD37t04evQoqlWr9sa+9vb2cHJywp07dwAAdnZ2yM7ORnJyslq/hIQE2NraFisOJiNEREQiK+9n0wiCAH9/f+zYsQNHjhyBs7PzW49JSkpCTEwM7O3tAQBeXl7Q19fHoUOHVH3i4uJw/fp1tGrVqlifn8M0REREYivnp/ZOmDABmzZtwm+//Qa5XK6a42FmZgYjIyOkpaUhJCQEffv2hb29PR48eIDPP/8cVlZW6N27t6qvn58fJk+eDEtLS1hYWGDKlCnw9PRUra4pKiYjREREWiYsLAwA0K5dO7X9a9euxciRI6Grq4tr167hp59+wvPnz2Fvb4/27dtjy5YtkMvlqv5LliyBnp4eBgwYgIyMDHTo0AHr1q2Drq5useJhMkJERCS2UrjPiFDMYZo3MTIywoEDB956HkNDQ4SGhiI0NLTI710YJiNEREQiK42bnpV8NY54mIwQERGJTNuTEa6mISIiIlGxMkJERCS2cl5NU9EwGSEiIhIZh2mIiIiIRMTKCBERkci0vTLCZISIiEhk2p6McJiGiIiIRMXKCBERkci0vTLCZISIiEhsWr60l8M0REREJCpWRoiIiETGYRoiIiISFZMRIiIiEpW2JyOcM0JERESiYmWEiIhIbFq+mobJCBERkcg4TENEREQkIlZGiIiIRKbtlREmI0RERCKToBSSEQ2eNMJhGiIiIhIVKyNEREQi4zANERERiYtLe6msffWtP4xkcrHD0AqH7ieKHYLWae9kKXYIWsVAj6Pr5eVFllLsELQGkxEiIiKRcZiGiIiIRMVkhIiIiEQlkeRvJT2HpuLgIxEREYmKlREiIiKR5VdGSjpMU0rBiIDJCBERkdhKYZhGk5f2cpiGiIiIRMXKCBERkci4moaIiIhExdU0RERERCJiZYSIiEhkOjoS6OiUrLQhlPB4MTEZISIiEhmHaYiIiIhExMoIERGRyLiahoiIiESl7cM0TEaIiIhEpu2VEc4ZISIiIlGxMkJERCQyba+MMBkhIiISmbbPGeEwDREREYmKlREiIiKRSVAKwzTQ3NIIkxEiIiKRcZiGiIiISESsjBAREYmMq2mIiIhIVBymISIiIhIRKyNEREQi0/ZhGlZGiIiIRPZymKakW1HNmzcPTZs2hVwuh42NDXr16oWoqCi1PoIgICQkBA4ODjAyMkK7du1w48YNtT5ZWVkICAiAlZUVZDIZevTogdjY2GJ/fiYjREREIntZGSnpVlTHjx/HhAkTcPbsWRw6dAhKpRKdO3dGenq6qs/ChQuxePFirFixAhcuXICdnR06deqE1NRUVZ/AwEDs3LkTv/zyC06ePIm0tDR0794dubm5xfr8HKYhIiKqRBQKhdprqVQKqVSqtm///v1qr9euXQsbGxtERETgvffegyAIWLp0KaZPn44+ffoAANavXw9bW1ts2rQJH3/8MVJSUrB69Wps2LABHTt2BAD8/PPPcHR0xJ9//glvb+8ix8zKCBERkdhKY4jmf4URR0dHmJmZqbZ58+a99e1TUlIAABYWFgCA6OhoxMfHo3Pnzqo+UqkUbdu2xenTpwEAERERyMnJUevj4OCAevXqqfoUFSsjREREIivNCawxMTEwNTVV7X+1KvIqQRAQFBSENm3aoF69egCA+Ph4AICtra1aX1tbWzx8+FDVx8DAAFWqVCnQ5+XxRcVkhIiIqBIxNTVVS0bext/fH1evXsXJkycLtL2aIAmC8NakqSh9XsVhGiIiIpGV92qalwICArB7924cPXoU1apVU+23s7MDgAIVjoSEBFW1xM7ODtnZ2UhOTn5tn6JiMkJERCSy8l5NIwgC/P39sWPHDhw5cgTOzs5q7c7OzrCzs8OhQ4dU+7Kzs3H8+HG0atUKAODl5QV9fX21PnFxcbh+/bqqT1FxmIaIiEjLTJgwAZs2bcJvv/0GuVyuqoCYmZnByMgIEokEgYGBmDt3Ltzc3ODm5oa5c+fC2NgYQ4YMUfX18/PD5MmTYWlpCQsLC0yZMgWenp6q1TVFxWSEiIhIZOX9bJqwsDAAQLt27dT2r127FiNHjgQABAcHIyMjA+PHj0dycjKaN2+OgwcPQi6Xq/ovWbIEenp6GDBgADIyMtChQwesW7cOurq6xYqdyQgREZHIyvt28IIgFOl8ISEhCAkJeW0fQ0NDhIaGIjQ0tMjvXRjOGSEiIiJRsTJCREQkMm1/UB6TESIiIpGV95yRiqbSJSMPHjyAs7MzLl++jIYNG4odToVx/24sjv15Af88egKFIh0jxvRAvQZuAIDc3Fzs//0U/r4RjaSk5zAylMK1lhO69vg/mJmbAABepGfg4N7TuP33QzxPToXMxAh167vCu3trGBm9+e5+2urhvVicPnYRj2MTkKZIx8CRvqjl6apqP3bgDK5fjoIiJRW6urqwr2aD931ao5qTvapPxJmruHY5CnGxCcjOysbUr8fB0MhQjI+jcQaO+xZPEp8X2N/LuzkCx/iq7Vu0ahd+P3QRE0Z2Rf/uxVuSSPlWbDiEP45fxd2HCTCU6qOJZw18Ps4XNav/e78JQRCweM1+bNp9Bs9TM9CoTnXMCeoHDxf7N5xZO2h7ZUTUOSMjR45UWx9taWmJLl264OrVq2KGVSllZ+XAoao1eg3oULAtW4l/Yp6go08LBE4dhuFjeuBpQjLWrdql6qNISUdKSjq6926LoM9HYOAHXRB18wF+3XigHD+FZsnOzoGtgzW69m5faLuldRV07dMe46YMw4f+A2BexQw//7AD6WkvVH1ycpRw9XDC/3VoWl5hVxqr5o/D9vCpqu3bmSMBAG1b1lXrd+L8Tdy8EwsrC3khZ6GiOnP5Hkb0aYPdqwKxeck4KHPzMGTSSrzIyFL1+X7jYYRvOYavgvpi749BsLE0xZBJYUh7kSli5FQRiD6BtUuXLoiLi0NcXBwOHz4MPT09dO/eXeywKp1adZ3RxbcNPBu6FWgzMpLio4D+aNDYAza2FnBydkCv/u8jNuYJkp/lP/3RzsEKI8b0QB3PmrCyNoerR3V08W2Nm9fvIzc3r7w/jkZwq+2M931ao3b9gtccADwb14KLuxOqWJrDxs4K3j3fQ1ZmNp48fqrq0+K9xmjToZlatYSKxtxMBssqctV2JiIKDnYWaFj335s7JSYpsOzHPfjik/7FXopI6jYuHosBXZvDw8UeddyqYvG0IfjnSTKuRsUCyK+KrP71LwQM74SubRuglos9lkwfioysbOw6GCFy9OIT6w6sFYXoyYhUKoWdnR3s7OzQsGFDTJ06FTExMUhMTHztMXl5eViwYAFcXV0hlUpRvXp1zJkzp9C+ubm58PPzg7OzM4yMjODh4YFly5ap9Tl27BiaNWsGmUwGc3NztG7dWvUgoCtXrqB9+/aQy+UwNTWFl5cXLl68WHoXoILKyMiCRII3DsFkZmbB0NAAurqi/zXSeLnKXEScuQapoRR2DtZih1Pp5OQoceivK+javrGqlJ2Xl4e5ob9iUM82cHYs3q2r6e0U6RkAAHNTYwDAo8dJSEhSoG2zWqo+UgM9tGjoiovXH4gRYoVS3ndgrWgq1JyRtLQ0bNy4Ea6urrC0tHxtv2nTpiE8PBxLlixBmzZtEBcXh7///rvQvnl5eahWrRq2bt0KKysrnD59Gh999BHs7e0xYMAAKJVK9OrVC2PGjMHmzZuRnZ2N8+fPq/5PHTp0KBo1aoSwsDDo6uoiMjIS+vr6hb5XVlYWsrL+LUkqFIoSXA3x5OQo8cdvJ9CwSW0YviYZSU/LwJ9/nEWL1vXLObrK5fbN+9i2YR9ycnIgl8sw7OM+MDYxEjusSufkhVtIS89El/aNVfs27zoBXR0d9O3aUsTIKidBEPBl6C40q++CWv+bD5L4LBUACgyHWVWR458nz8o9RqpYRE9G9uzZAxOT/EmS6enpsLe3x549e6CjU/hv26mpqVi2bBlWrFiBESNGAABq1qyJNm3aFNpfX18fs2fPVr12dnbG6dOnsXXrVgwYMAAKhQIpKSno3r07atasCQCoXbu2qv+jR4/w6aefolat/Gzeza3wkjsAzJs3T+29NFFubi42rt0DQRDQp5D5JQCQmZGFNSt3wtbeEp34RV4iNWo6YuzkD/AiPQMRZ69h24a9GD1xMGRyY7FDq1T2HY5A80ZusLLIf5Jp1L1/sG3fGYQvHK/Rv01WVF8s3o5b9x5jx/efFGh79WoLEArZq30kKIXVNKUSiThEr6+3b98ekZGRiIyMxLlz59C5c2f4+PiohkledevWLWRlZaFDh8J/UBZm5cqVaNKkCaytrWFiYoLw8HA8evQIAGBhYYGRI0fC29sbvr6+WLZsGeLi4lTHBgUFYfTo0ejYsSPmz5+Pe/fuvfZ9pk2bhpSUFNUWExNT5BgrgtzcXGxYvQfPkhQY49+v0KpIZmY2fvx+Owyk+hgxpifH2UvIQKoPCytzVHOyR8+BnaGjo4NL56+LHValEp+YjIhr99CtQxPVvqu3HuJ5SjoGjP0W7w+YifcHzMSTxOcI++kPDBz3rYjRar4vlmzHwVPXsXW5PxxszFX7rf9XEXlZIXkpKTlN1abNdCSSUtk0lejJiEwmg6urK1xdXdGsWTOsXr0a6enpCA8PL7S/kVHxSthbt27FpEmTMGrUKBw8eBCRkZH48MMPkZ2dreqzdu1anDlzBq1atcKWLVvg7u6Os2fPAgBCQkJw48YNdOvWDUeOHEGdOnWwc+fOQt9LKpXC1NRUbdMULxORp4nJ+Mi/H2SFDBVkZmQhfMU26Orq4sOPe0FfX/TCWqUjCAJylblih1Gp/HHkEsxNZWjh5a7a17ltQ6xe5I8fv52g2qws5BjYow2++WKEiNFqLkEQMH3xNvxx/Cq2LJuA6g7qQ+3VHSxhY2mKvy5EqfZl5yhxNvIumtSrUc7RUkVT4X6aSCQS6OjoICMjo9B2Nzc3GBkZ4fDhwxg9evRbz3fixAm0atUK48ePV+0rrLrRqFEjNGrUCNOmTUPLli2xadMmtGjRAgDg7u4Od3d3TJo0CYMHD8batWvRu3fvd/yE4sjKysbT/9xz4VmSAv/EJsDY2BCmZib46cff8U/ME4wa2xt5ggCFIh0AYGxsCD09XWRmZiP8u+3Izs7B4BFdkZmZjczM/ITOxMTotcNq2iw7KxvPnj5XvU5+pkD8PwkwMjaEkbERThw+B4+6NWEilyHjRQYunLoKRUoa6jT4dygwTZGOtNR01XmexD2FVGoAsyqmMDLm/UbeJi8vD/uPXoJ3u0bQ+08Vz0xuDLNXhsJ0dXVhYS5H9aqcQPwupi/ahl1/RmD1vNEwMZYiISl/zpzcxBBGUgNIJBL49X8PKzYcgnM1azg7WiP0p0MwkhqgV2cvkaMXH296JrKsrCzVo4uTk5OxYsUKpKWlwdfXt9D+hoaGmDp1KoKDg2FgYIDWrVsjMTERN27cgJ+fX4H+rq6u+Omnn3DgwAE4Oztjw4YNuHDhApyd85f3RUdH44cffkCPHj3g4OCAqKgo3L59G8OHD0dGRgY+/fRT9OvXD87OzoiNjcWFCxfQt2/fsrsgZST24ROsXL5V9fr3HccAAF7N66Jz15a4eS0/QVsyf4PacWMnDkBNd0f88+gJHj3IH75aMHu1Wp9ps0fDwtKsDKPXTI9jnmB92DbV64O7jwMAGjSpg+79OuBpQjKuXPgdL9IzYSQzRFVHW3w4YQBs7KxUx1w8cxXHD55VvV733a8AgJ4DO6NhM/X7ZVBBEVfv4cnTFHR9nz/sytpPu04BAPoHrFDbv/jzwRjQtTkAYPzQDsjMysH0xduQkvoCDes4YeOScTBhYq31Nz2TCEV5dF8ZGTlyJNavX696LZfLUatWLUydOvWNP/Dz8vIwb948hIeH4/Hjx7C3t8fYsWMxbdq0AndgzcrKwtixY7Fz505IJBIMHjwYZmZm+OOPPxAZGYknT55g7NixOHfuHJKSkmBvb48RI0Zg1qxZUCqVGDFiBE6dOoUnT57AysoKffr0wTfffANDw7f/41EoFDAzM8PCA1dgJOOYaHlIy+I9T8pbe6fXr3yj0udqZyJ2CFojVaGAs4MlUlJSymzY/eXPiY6LDkPPSFaicykz0vHn5A5lGm9ZETUZqeyYjJQ/JiPlj8lI+WIyUn6YjJQf0YdpiIiItJ6kFIZZNHeUhskIERGR2LR9AiuXQBAREZGoWBkhIiISmeR//5X0HJqKyQgREZHIdCT5W0nPoak4TENERESiYmWEiIhIZNp+0zMmI0RERCLT9tU0RUpGli9fXuQTTpw48Z2DISIiIu1TpGRkyZIlRTqZRCJhMkJERFRMOhIJdEpY2ijp8WIqUjISHR1d1nEQERFpLW0fpnnn1TTZ2dmIioqCUqkszXiIiIi0zssJrCXdNFWxk5EXL17Az88PxsbGqFu3Lh49egQgf67I/PnzSz1AIiIiqtyKnYxMmzYNV65cwbFjx2BoaKja37FjR2zZsqVUgyMiItIGL4dpSrppqmIv7d21axe2bNmCFi1aqJWE6tSpg3v37pVqcERERNpA2yewFrsykpiYCBsbmwL709PTNXq8ioiIiMRR7GSkadOm2Lt3r+r1ywQkPDwcLVu2LL3IiIiItISklDZNVexhmnnz5qFLly64efMmlEolli1bhhs3buDMmTM4fvx4WcRIRERUqWn77eCLXRlp1aoVTp06hRcvXqBmzZo4ePAgbG1tcebMGXh5eZVFjERERFSJvdOzaTw9PbF+/frSjoWIiEgr6Ujyt5KeQ1O9UzKSm5uLnTt34tatW5BIJKhduzZ69uwJPT0+d4+IiKi4tH2YptjZw/Xr19GzZ0/Ex8fDw8MDAHD79m1YW1tj9+7d8PT0LPUgiYiIqPIq9pyR0aNHo27duoiNjcWlS5dw6dIlxMTEoH79+vjoo4/KIkYiIqJKT1tveAa8Q2XkypUruHjxIqpUqaLaV6VKFcyZMwdNmzYt1eCIiIi0gbYP0xS7MuLh4YEnT54U2J+QkABXV9dSCYqIiEibvJzAWtJNUxUpGVEoFKpt7ty5mDhxIrZt24bY2FjExsZi27ZtCAwMxIIFC8o6XiIiIqpkijRMY25urlb+EQQBAwYMUO0TBAEA4Ovri9zc3DIIk4iIqPLS9mGaIiUjR48eLes4iIiItFZp3M5dc1ORIiYjbdu2Les4iIiISEu9813KXrx4gUePHiE7O1ttf/369UscFBERkTbRkUigU8JhlpIeL6ZiJyOJiYn48MMP8ccffxTazjkjRERExVMa9wrR4Fyk+Et7AwMDkZycjLNnz8LIyAj79+/H+vXr4ebmht27d5dFjERERFSJFbsycuTIEfz2229o2rQpdHR04OTkhE6dOsHU1BTz5s1Dt27dyiJOIiKiSkvbV9MUuzKSnp4OGxsbAICFhQUSExMB5D/J99KlS6UbHRERkRYo6a3gNf2W8O90B9aoqCgAQMOGDbFq1Sr8888/WLlyJezt7Us9QCIiIqrcij1MExgYiLi4OADArFmz4O3tjY0bN8LAwADr1q0r7fiIiIgqPa6mKaahQ4eq/tyoUSM8ePAAf//9N6pXrw4rK6tSDY6IiEgbcDVNCRkbG6Nx48ZMRIiIiN7RywmsJd2K46+//oKvry8cHBwgkUiwa9cutfaRI0cWOH+LFi3U+mRlZSEgIABWVlaQyWTo0aMHYmNji/35i1QZCQoKKvIJFy9eXOwgiIiIqHylp6ejQYMG+PDDD9G3b99C+3Tp0gVr165VvTYwMFBrDwwMxO+//45ffvkFlpaWmDx5Mrp3746IiAjo6uoWOZYiJSOXL18u0sk0eVlRWermbg+5qanYYWiF63EpYoegde6lpIkdglaxkkvFDkFrpL7IKbf30kHJhypeHq9QKNT2S6VSSKUF/974+PjAx8fnjeeUSqWws7MrtC0lJQWrV6/Ghg0b0LFjRwDAzz//DEdHR/z555/w9vYucux8UB4REZHISvM+I46Ojmr7Z82ahZCQkHc657Fjx2BjYwNzc3O0bdsWc+bMUd3eIyIiAjk5OejcubOqv4ODA+rVq4fTp0+XfjJCREREmiEmJgam/6nGF1YVKQofHx/0798fTk5OiI6OxowZM/D+++8jIiICUqkU8fHxMDAwQJUqVdSOs7W1RXx8fLHei8kIERGRyCQSQKeUVtOYmpqqJSPvauDAgao/16tXD02aNIGTkxP27t2LPn36vPY4QRCKXeUp8WoaIiIiKhkdSelsZcne3h5OTk64c+cOAMDOzg7Z2dlITk5W65eQkABbW9tinZvJCBEREb1VUlISYmJiVHdb9/Lygr6+Pg4dOqTqExcXh+vXr6NVq1bFOjeHaYiIiEQmxoPy0tLScPfuXdXr6OhoREZGwsLCAhYWFggJCUHfvn1hb2+PBw8e4PPPP4eVlRV69+4NADAzM4Ofnx8mT54MS0tLWFhYYMqUKfD09FStrimqd6qMbNiwAa1bt4aDgwMePnwIAFi6dCl+++23dzkdERGRVhNjmObixYto1KgRGjVqBCD/nmKNGjXCzJkzoauri2vXrqFnz55wd3fHiBEj4O7ujjNnzkAul6vOsWTJEvTq1QsDBgxA69atYWxsjN9//71Y9xgB3qEyEhYWhpkzZyIwMBBz5sxBbm4uAMDc3BxLly5Fz549i3tKIiIiKmft2rWDIAivbT9w4MBbz2FoaIjQ0FCEhoaWKJZiV0ZCQ0MRHh6O6dOnq2U+TZo0wbVr10oUDBERkTZ6+Wyakm6aqtiVkejoaFVJ57+kUinS09NLJSgiIiJtou1P7S12ZcTZ2RmRkZEF9v/xxx+oU6dOacRERESkVXRKadNUxa6MfPrpp5gwYQIyMzMhCALOnz+PzZs3Y968efjxxx/LIkYiIiKqxIqdjHz44YdQKpUIDg7GixcvMGTIEFStWhXLli3DoEGDyiJGIiKiSq005nxo8CjNu91nZMyYMRgzZgyePn2KvLw81UNziIiIqPh0UApzRqC52UiJbnpmZWVVWnEQERGRlip2MuLs7PzGu7zdv3+/RAERERFpGw7TFFNgYKDa65ycHFy+fBn79+/Hp59+WlpxERERaY3SeNBdWT8orywVOxn55JNPCt3/3Xff4eLFiyUOiIiIiLRLqS1L9vHxwfbt20vrdERERFpDIvn3xmfvumnVMM3rbNu2DRYWFqV1OiIiIq3BOSPF1KhRI7UJrIIgID4+HomJifj+++9LNTgiIiKq/IqdjPTq1UvttY6ODqytrdGuXTvUqlWrtOIiIiLSGpzAWgxKpRI1atSAt7c37OzsyiomIiIirSL5338lPYemKtYEVj09PYwbNw5ZWVllFQ8REZHWeVkZKemmqYq9mqZ58+a4fPlyWcRCREREWqjYc0bGjx+PyZMnIzY2Fl5eXpDJZGrt9evXL7XgiIiItAHnjBTRqFGjsHTpUgwcOBAAMHHiRFWbRCKBIAiQSCTIzc0t/SiJiIgqMYlE8sZHrRT1HJqqyMnI+vXrMX/+fERHR5dlPERERKRlipyMCIIAAHByciqzYIiIiLQRh2mKQZNLQERERBUV78BaDO7u7m9NSJ49e1aigIiIiEi7FCsZmT17NszMzMoqFiIiIq308mF3JT2HpipWMjJo0CDY2NiUVSxERERaSdvnjBT5pmecL0JERERlodiraYiIiKiUlcIEVg1+NE3Rk5G8vLyyjIOIiEhr6UACnRJmEyU9XkzFvh08ERERlS5tX9pb7AflEREREZUmVkaIiIhEpu2raZiMEBERiYz3GSGttGn3aWzefRqxT/LvmOvmZIcJwzqhbfPaBfrOWPwrtuw9i8/H98TIvu+Vd6iVRkZGFjZtO4ZzF/+GQpEO5xp2GPWBN9xqVoVSmYtN247iUuRdPElMhrGRFPXruWDYwA6wqCIXO3SNEBX1CAcOnMODB0+QkpKGCRP6oHFjd1W7IAjYvfskjh+/ghcvMuHiYo+hQzujalVrVZ+UlDRs3XoUN28+QGZmNuzsLNCtW0s0aVJLjI+k0cJ/OYJla//AB73a4LNxPQu0z162Db/uO4epH/fAsD7/J0KEVJFUyjkjEokEu3btEjuMCs3OygyTx3TDju8nYcf3k9CikSvGz1yLOw/i1fodOnkNV/5+BBtLU5EirTy++/F3XL1+H5+M64Ul88aiQT0XzJ7/M5KeKZCVnYP7D+LQv9f/4duvxiA4cAAexyVh3uJfxA5bY2Rn56BaNVsMHdqp0PY//jiHgwcvYOjQTvjiixEwNTXBokVbkJGRperz44978OTJMwQE9MWXX/qhcWN3rFz5Gx4+jC/0nFS4a1Ex2LbvLNyd7QttP3z6Oq7ye0XNywmsJd00lejJSHx8PAICAuDi4gKpVApHR0f4+vri8OHDYodWqb3fqi7aNa8NZ0drODtaI8ivK4yNDBB586GqT3xiCr4M3YlFnw+Fvp6uiNFqvqzsHJy9cAvDBnVA3VpOsLezwKC+7WBjbY4Dhy9CZmyIkM+GoXWLuqjqYAUP12oYPbwL7kXHIfFpitjhawRPz5ro0+c9eHl5FGgTBAF//nkB3bq1gpeXB6pVs4afXzdkZ+fg3Lmbqn737v2D99/3gouLA6ytzeHr2xrGxlI8evSkPD+KRnuRkYXPFmxCSGA/mMqNCrQ/eZqCud/twoKpQ6DH7xUVHUhUQzXvvGnw0l5Rk5EHDx7Ay8sLR44cwcKFC3Ht2jXs378f7du3x4QJE8QMTavk5uZhz5HLeJGZjUZ1nADk31cmeP4mjB7QDm417ESOUPPl5eYhL0+Agb76yKiBgR5uRcUUesyLjCxIJIDM2LA8QqzUnj5NQUpKOurWraHap6+vBw8PR9y7949qn5tbNVy4cAtpaRnIyxNw7txNKJW58PCoLkLUmunrFTvxXrPaaPmfIbKX8vLyMG3hZozs1xau/F6h/xA1GRk/fjwkEgnOnz+Pfv36wd3dHXXr1kVQUBDOnj37xmPXrFmDunXrQiqVwt7eHv7+/q/tO3XqVLi7u8PY2BguLi6YMWMGcnJyVO1XrlxB+/btIZfLYWpqCi8vL1y8eBEA8PDhQ/j6+qJKlSqQyWSoW7cu9u3bV+j7ZGVlQaFQqG0VWdT9ODTsNg31ukzFrKXb8N3sD1VfED/8chS6ujoYzrHcUmFkJIWHWzX8uusEniWnIjcvD8dPXsWde/8g+Xlagf7Z2Ur8vOUw/q+lJ4yNpSJEXLmkpORfY1NTmdp+U1MZUlLSVa8//rgn8vLy8MknyzB27DfYsOEAJkzoAxubKuUar6badywSt+7+g8BRPoW2r956DLq6OvigV5tyjqzi0/ZhGtEmsD579gz79+/HnDlzIJPJCrSbm5u/9tiwsDAEBQVh/vz58PHxQUpKCk6dOvXa/nK5HOvWrYODgwOuXbuGMWPGQC6XIzg4GAAwdOhQNGrUCGFhYdDV1UVkZCT09fUBABMmTEB2djb++usvyGQy3Lx5EyYmJoW+z7x58zB79uxiXAVxOTta47cfJkORloEDJ65i6oLN2Lh4PDKzc/DTjhPYuXISn0lUij4Z2wsrwndjdMAS6OhI4FLDHv/X0hP3H8Sp9VMqc7H4u+3IyxPw0ciuIkVbOb3691kQ1L/Ad+78C+npmZg8eRDkciNcunQHYWG78NlnQ1GtGh8S+iZxCc8xP+w3/DB3DKQG+gXab9yJxc+7TuDX7wL5vVIIHZS8OiD6vIsSEC0ZuXv3LgRBQK1axZ+l/vXXX2Py5Mn45JNPVPuaNm362v5ffPGF6s81atTA5MmTsWXLFlUy8ujRI3z66aeqWNzc3FT9Hz16hL59+8LT0xMA4OLi8tr3mTZtGoKCglSvFQoFHB0di/npyo+Bvh6cqloBADw9HHEtKgbrd5xATSdbJD1PQ7vBX6v65ublYf7K3Vi//S8c3fTF605Jb2Bna4GvvxiJzMxsvMjIgkUVOb4N3QYba3NVH6UyF9+GbsOTxOf4ctowVkVKiZlZ/i8QKSlpMDf/95eJ1NR0VbUkISEZR45cwpdf+qlW2Dg62uLOnRgcOXIJw4d3Kf/ANcjNu7F49jwNA/2Xqfbl5uUh4lo0Nu8+jUl+XfHseTo6fTBXrf2b8N+xYdcJHPzpczHCpgpCtGTk5YP3ipshJyQk4PHjx+jQoUORj9m2bRuWLl2Ku3fvIi0tDUqlEqam/87iDgoKwujRo7FhwwZ07NgR/fv3R82aNQEAEydOxLhx43Dw4EF07NgRffv2Rf369Qt9H6lUCqlUc394CIKA7Bwlenb0QqvGbmpto6b+gJ6dvNC3SzORoqs8DA0NYGhogLT0DEReu4fhgzoC+DcRiXvyDF9+PhxyubHIkVYeVlZmMDOT4ebNB3Byyh+KVCpzERUVg3792gHIX40DFPxO0tHR4YNCi6BFQ1fsXDVZbd8Xi7bA2dEGfgPaw9pCjtZN1CcXf/x5OHw7eKFX5yblGWqFJJFISlwx0uSKk2hVHTc3N0gkEty6datYxxkZFZyd/SZnz57FoEGD4OPjgz179uDy5cuYPn06srOzVX1CQkJw48YNdOvWDUeOHEGdOnWwc+dOAMDo0aNx//59DBs2DNeuXUOTJk0QGhparBgqokU/7sOFq/cRG/8MUffjsHj1Ppy/cg89OjRGFTMZ3J3t1TZ9PV1YW5jCxZGl6nd1+epdXLpyF08SkhF57R5mzvkJVe0t8f57DZGbm4dvlv+Ke9FxCBzXG3l5ApKfpyH5eRpylLlih64RMjOz8ejRE9XKl6dPn+PRoydISkqBRCJBx45NsXfvGVy6FIXY2ESsWbMXBgb6aN68DgDAzs4SNjZV8NNP+3H//mMkJCTjwIFzuHkzGo0aFZyMSepkxoZwq2GnthkZGsBcbgy3GnYwN5UVaNfT04VVFTmc+b0CSSltmkq0yoiFhQW8vb3x3XffYeLEiQXmjTx//rzQeSNyuRw1atTA4cOH0b59+7e+z6lTp+Dk5ITp06er9j18+LBAP3d3d7i7u2PSpEkYPHgw1q5di969ewMAHB0dMXbsWIwdOxbTpk1DeHg4AgICivmJK5ak5FQEz9+EhGcKyGVG8HCxx+p5Ywr85kKl58WLLPy89QiSnilgIjNCy2a1MaR/e+jp6SIh8TkuXLoNAJg8/Qe14778fDjq1akhQsSa5cGDOHzzzWbV6y1bjgAAWrWqBz+/7vDxaY6cnBz8/PNBpKdnwsXFAUFBA2FklF/N1NPTRWBgf2zbdgyhoduQmZkDGxtzjBrVHfXr1xTlM5H20PY7sEoEEeuP0dHRaNWqFSwsLPDll1+ifv36UCqVOHToEMLCwl5bNVm/fj3Gjh2LBQsWwMfHB6mpqTh16pQqQZBIJNi5cyd69eqF3377Df369cOGDRvQtGlT7N27F7Nnz0Zubi6eP3+OjIwMfPrpp+jXrx+cnZ0RGxuLESNGoG/fvliwYAECAwPh4+MDd3d3JCcnY9y4cahRowa2bNny1s+nUChgZmaGG9EJkJvy5j7l4Xoc78lR3pKzst/eiUpN82qWYoegNVJTFWjkaoeUlBS1of3S9PLnxA/HbsLIpGR3W85IS8VH7eqUabxlRdTbwTs7O+PSpUuYM2cOJk+ejLi4OFhbW8PLywthYWGvPW7EiBHIzMzEkiVLMGXKFFhZWaFfv36F9u3ZsycmTZoEf39/ZGVloVu3bpgxYwZCQkIAALq6ukhKSsLw4cPx5MkTWFlZoU+fPqpVMbm5uZgwYQJiY2NhamqKLl26YMmSJaV+LYiISLtpbl2j5EStjFR2rIyUP1ZGyh8rI+WLlZHyU56VkfDjN2FcwsrIi7RUjGmrmZURTV6WTERERJUAn9pLREQkMm1f2stkhIiISGTafgdWTY6diIiIKgFWRoiIiETGYRoiIiISVWncQVVzUxEO0xAREWmlv/76C76+vnBwcIBEIsGuXbvU2gVBQEhICBwcHGBkZIR27drhxo0ban2ysrIQEBAAKysryGQy9OjRA7GxscWOhckIERGRyF4O05R0K4709HQ0aNAAK1asKLR94cKFWLx4MVasWIELFy7Azs4OnTp1QmpqqqpPYGAgdu7ciV9++QUnT55EWloaunfvjtzc4j1Ti8M0REREIhNjNY2Pjw98fHwKbRMEAUuXLsX06dPRp08fAPmPYrG1tcWmTZvw8ccfIyUlBatXr1Y98R4Afv75Zzg6OuLPP/+Et7d3mcVOREREpaw0KyMKhUJty8rKKnY80dHRiI+PR+fOnVX7pFIp2rZti9OnTwMAIiIikJOTo9bHwcEB9erVU/UpKiYjRERElYijoyPMzMxU27x584p9jvj4eACAra2t2n5bW1tVW3x8PAwMDFClSpXX9ikqDtMQERGJrDRX08TExKg9m0Yqlb77OV+ZhyIIwlvnphSlz6tYGSEiIhKZRFI6GwCYmpqqbe+SjNjZ2QFAgQpHQkKCqlpiZ2eH7OxsJCcnv7ZPUTEZISIiIjXOzs6ws7PDoUOHVPuys7Nx/PhxtGrVCgDg5eUFfX19tT5xcXG4fv26qk9RcZiGiIhIZDqQQKeEAzXFPT4tLQ13795VvY6OjkZkZCQsLCxQvXp1BAYGYu7cuXBzc4Obmxvmzp0LY2NjDBkyBABgZmYGPz8/TJ48GZaWlrCwsMCUKVPg6empWl1TVExGiIiIRPbfYZaSnKM4Ll68iPbt26teBwUFAQBGjBiBdevWITg4GBkZGRg/fjySk5PRvHlzHDx4EHK5XHXMkiVLoKenhwEDBiAjIwMdOnTAunXroKurW7zYBUEQihc+FZVCoYCZmRluRCdA/p/JRFR2rseliB2C1knOyhY7BK3SvJql2CFojdRUBRq52iElJUVtQmhpevlzYsuZOzA2kb/9gDd4kZaKgS3dyjTessLKCBERkcgk//uvpOfQVExGiIiIRCbGME1FwtU0REREJCpWRoiIiEQmKYXVNBymISIionem7cM0TEaIiIhEpu3JCOeMEBERkahYGSEiIhIZl/YSERGRqHQk+VtJz6GpOExDREREomJlhIiISGQcpiEiIiJRcTUNERERkYhYGSEiIhKZBCUfZtHgwgiTESIiIrFxNQ0RERGRiFgZISIiEhlX0xAREZGotH01DZMRIiIikUlQ8gmoGpyLcM4IERERiYuVESIiIpHpQAKdEo6z6GhwbYTJSDkwl+nDVKYvdhhaoX5Vc7FD0DpxyRlih0Ck8ThMQ0RERCQiVkaIiIjEpuWlESYjREREItP2+4xwmIaIiIhExcoIERGR2ErhpmcaXBhhMkJERCQ2LZ8ywmEaIiIiEhcrI0RERGLT8tIIkxEiIiKRaftqGiYjREREItP2p/ZyzggRERGJipURIiIikWn5lBEmI0RERKLT8myEwzREREQkKlZGiIiIRMbVNERERCQqrqYhIiIiEhErI0RERCLT8vmrTEaIiIhEp+XZCIdpiIiISFSsjBAREYmMq2mIiIhIVNq+mobJCBERkci0fMoI54wQERGRuFgZISIiEpuWl0aYjBAREYlM2yewcpiGiIiIRMXKCBERkci4moaIiIhEpeVTRjhMQ0REROJiMkJERCQ2SSltRRQSEgKJRKK22dnZqdoFQUBISAgcHBxgZGSEdu3a4caNGyX/nK/BZISIiEhkklL6rzjq1q2LuLg41Xbt2jVV28KFC7F48WKsWLECFy5cgJ2dHTp16oTU1NTS/ugAmIwQERFpJT09PdjZ2ak2a2trAPlVkaVLl2L69Ono06cP6tWrh/Xr1+PFixfYtGlTmcTCZISIiEhkL1fTlHQDAIVCobZlZWUV+p537tyBg4MDnJ2dMWjQINy/fx8AEB0djfj4eHTu3FnVVyqVom3btjh9+nSZfH4mI0RERCIrzSkjjo6OMDMzU23z5s0r8H7NmzfHTz/9hAMHDiA8PBzx8fFo1aoVkpKSEB8fDwCwtbVVO8bW1lbVVtq4tJeIiEhspbi2NyYmBqampqrdUqm0QFcfHx/Vnz09PdGyZUvUrFkT69evR4sWLfJP98qNSwRBKLCvtLAyQkREVImYmpqqbYUlI6+SyWTw9PTEnTt3VKtqXq2CJCQkFKiWlBYmI0RERCITYzXNf2VlZeHWrVuwt7eHs7Mz7OzscOjQIVV7dnY2jh8/jlatWpXGxy2AwzRERERiK4XbwRcnF5kyZQp8fX1RvXp1JCQk4Ouvv4ZCocCIESMgkUgQGBiIuXPnws3NDW5ubpg7dy6MjY0xZMiQEgZZOCYjREREWiY2NhaDBw/G06dPYW1tjRYtWuDs2bNwcnICAAQHByMjIwPjx49HcnIymjdvjoMHD0Iul5dJPBJBEIQyOTNBoVDAzMwM/yQkq00mqqjS0jMx74e92Hf8Kp4mp8HTvSrmTOqLRnWcxA6tyFIylGKH8FobfzuFTbtPIzb+GQDArYYdAoZ3RtvmtQEAB/66is2/n8GN27FIVqRjd/hk1HGtKmbIRRKXnCF2CIXq//E3iE98XmB/7y7NEfRRDwiCgLVbjmD3oQtITc9AHTdHBI3xhXP1shkTLy1VZAZih1Ak4b8cwbK1f+CDXm3w2bieBdpnL9uGX/edw9SPe2BYn/8TIcK3S01VoJGrHVJSUsrsO/zlz4nLd+Mhl5fsPcoj3rLCOSOvsW7dOpibm6teh4SEoGHDhqLFUx4C527G8fNR+G7WMBz/+TO0a1YLfQO+Q1zCc7FDqxTsrM3x6Zhu2LVyEnatnISWjdww9os1uB2dP0nsRWY2vOrVwJSPuokcaeXww8Lx2LX6M9W2ZNaHAID2reoBADbtPIEtv5/CpDG+CF8wHhbmJpg0ey1eZBR+TwYqumtRMdi27yzcne0LbT98+jqu/v0INpaa9QOzTJXz7eArmkqfjIwcObLA/fclEgnu3r37xuMGDhyI27dvl1OU4svIzMaeY1cw078nWjVyhYujNYLHdEV1B0us3XFS7PAqhQ6t6qJdizpwdrSBs6MNJo/uCmMjA0TefAAA6N25CQJGeKO1l7u4gVYSVcxksKwiV22nL0ahqp0FGtZ1hiAI2LrnFIb3bYe2LerCxckW0yf2Q1ZWDg79dUXs0DXai4wsfLZgE0IC+8FUblSg/cnTFMz9bhcWTB0CPT1dESKkiqjSJyMA0KVLF7X778fFxcHZ2fmNxxgZGcHGxqacIhRfbm4ecnPzYGigPo3ISKqPc1fuixRV5ZWbm4c9Ry7jRWY2GtWtIXY4lV5OjhIH/4pE1/e9IJFIEPckGc+ep6FpQ1dVHwN9PTSsWwPXox6JGKnm+3rFTrzXrDZaNi6YVOfl5WHaws0Y2a8tXGvYFXK09hJ7NY3YtCIZkUqlavfft7Ozw7Jly+Dp6QmZTAZHR0eMHz8eaWlpqmNeHaap7ExkhmjqWQOL1hxAfGIKcnPz8OsfFxBx4yGeJCnEDq/SiLr/GPV9PkOdzsGYsfhXhH35Idz4pVzmTpy/hbT0THR9vzEAIOl5/sO+LMxN1PpVMTdRtVHx7TsWiVt3/0HgKJ9C21dvPQZdXR180KtNOUdW8ZXm7eA1kVYkI4XR0dHB8uXLcf36daxfvx5HjhxBcHBwic6ZlZVV4JkAmuS7WcMgQICn7wxUfS8I4b8eR9/OXtDV0eC/4RWMs6MNdv84Gdu+/wRDerbCp/M3486Dsrm9Mv1rz+GLaN7YDVYWb56jIAjQ6N8uxRSX8Bzzw37DvODBkBroF2i/cScWP+86gTlTBpbZXTxJc2nF0t49e/bAxOTf34B8fHzw66+/ql47Ozvjq6++wrhx4/D999+/8/vMmzcPs2fPLlGsYnKuZo3dYZ8gPSMLqemZsLMyw+jpa1HdwVLs0CoNA3091Kia/2RMTw9HXPs7Buu3/4WvJw8QObLKKz4hGRFX7+Hr4H/vj2Bpnr888dnzNLUE5XlKWoFqCRXNzbuxePY8DQP9l6n25eblIeJaNDbvPo1Jfl3x7Hk6On0wV639m/DfsWHXCRz86XMxwq4wSvFu8BpJK5KR9u3bIywsTPVaJpPh6NGjmDt3Lm7evAmFQgGlUonMzEykp6dDJpO90/tMmzYNQUFBqtcKhQKOjo4ljr+8yYykkBlJ8VzxAkfP/Y1Z/j3EDqnSEgQgOydX7DAqtX1HLsHcVIaWXh6qffa2VWBhboILV+7C3cUBQP68ksgbDzB2mLdYoWq0Fg1dsXPVZLV9XyzaAmdHG/gNaA9rCzlaN/FQa//483D4dvBCr85NyjPUiknLsxGtSEZkMhlcXf+dqPbw4UN07doVY8eOxVdffQULCwucPHkSfn5+yMnJeef3kUqlRXoGQEV15OwtCIIAVydbRMckImTFb3CtboPB3VuIHVql8G34XrRtXhv2NuZIf5GJPUcice7KXaxZ8BEA4LkiHY8TniPhaQoAIPpRAgDA2kIO67cML1Dh8vLysO/IJfi0bww93X9XbkgkEgzo3ho/bz8OR3tLVLO3woYdxyCV6qPTew1EjFhzyYwNC8x/MjI0gLncWLXf3FT9Fz09PV1YVZHD2VF7Fgu8TmlMQNXkIUatSEZedfHiRSiVSixatAg6OvnTZrZu3SpyVOJTpGVgTtjveJzwHOamMnRv3wDTx3aHPpfflYqnyamYMncjEp4pIJcZoZaLPdYs+Aht/vfb4uHTNzB1wS+q/p98tQEAEDCiMz4Z2UWUmDXdxav38OTpc3Tt4FWgbUjv/0NWdg4W/bAbaemZqO1WDYtnfghjI839hYJIU2llMlKzZk0olUqEhobC19cXp06dwsqVK8UOS3S9OjZGr46NxQ6j0pofPOiN7X27NEPfLs3KKRrt0KyhG07smFNom0QiwahBHTBqUIdyjkp7rPtm3BvbtX2eyH9JUPLVMJpbF9HS1TQNGzbE4sWLsWDBAtSrVw8bN27EvHnzxA6LiIi0lJbfgJXPpilLmvZsmsqgIj+bprKqqM+mqaw05dk0lUF5PpvmRnQC5CV8j1SFAnWdbTTy2TRaOUxDRERUkZTGTcs0+fYtTEaIiIhEp91re7VyzggRERFVHKyMEBERiYzDNERERCQq7R6k4TANERERiYyVESIiIpFxmIaIiIhExWfTEBERkbi0fNII54wQERGRqFgZISIiEpmWF0aYjBAREYlN2yewcpiGiIiIRMXKCBERkci4moaIiIjEpeWTRjhMQ0RERKJiZYSIiEhkWl4YYTJCREQkNq6mISIiIhIRKyNERESiK/lqGk0eqGEyQkREJDIO0xARERGJiMkIERERiYrDNERERCLT9mEaJiNEREQi0/bbwXOYhoiIiETFyggREZHIOExDREREotL228FzmIaIiIhExcoIERGR2LS8NMJkhIiISGRcTUNEREQkIlZGiIiIRMbVNERERCQqLZ8ywmSEiIhIdFqejXDOCBEREYmKlREiIiKRaftqGiYjREREIuMEViozgiAAAFJTFSJHoj1SM5Rih6B10lIzxA5Bq+jlGYgdgtZIS00F8O93eVlSKEr+c6I0ziEWJiNlKPV/f5Fr1XQSORIiInpXqampMDMzK5NzGxgYwM7ODm7OjqVyPjs7OxgYaF7CKhHKI+XTUnl5eXj8+DHkcjkkGlQ/UygUcHR0RExMDExNTcUOp9Lj9S5/vOblS1OvtyAISE1NhYODA3R0ym69R2ZmJrKzs0vlXAYGBjA0NCyVc5UnVkbKkI6ODqpVqyZ2GO/M1NRUo744NB2vd/njNS9fmni9y6oi8l+GhoYamUCUJi7tJSIiIlExGSEiIiJRMRmhAqRSKWbNmgWpVCp2KFqB17v88ZqXL15vehtOYCUiIiJRsTJCREREomIyQkRERKJiMkJERESiYjJCao4dOwaJRILnz5+LHYpWePDgASQSCSIjI8UORatIJBLs2rVL7DC02rp162Bubq56HRISgoYNG4oWD4mLyUglcPr0aejq6qJLly5ih1KpjRw5EhKJRLVZWlqiS5cuuHr1qtihVWrx8fEICAiAi4sLpFIpHB0d4evri8OHD4sdGqHgv4uX2927d9943MCBA3H79u1yipIqOiYjlcCaNWsQEBCAkydP4tGjR2KHU6l16dIFcXFxiIuLw+HDh6Gnp4fu3buLHVal9eDBA3h5eeHIkSNYuHAhrl27hv3796N9+/aYMGGC2OHR//z338XLzdnZ+Y3HGBkZwcbGppwipIqOyYiGS09Px9atWzFu3Dh0794d69ate+sxWVlZCA4OhqOjI6RSKdzc3LB69epC+yYlJWHw4MGoVq0ajI2N4enpic2bN6v12bZtGzw9PWFkZARLS0t07NgR6enpAPKHfZo1awaZTAZzc3O0bt0aDx8+LPHnFotUKoWdnR3s7OzQsGFDTJ06FTExMUhMTHztMXl5eViwYAFcXV0hlUpRvXp1zJkzp9C+ubm58PPzg7OzM4yMjODh4YFly5ap9XnTNb1y5Qrat28PuVwOU1NTeHl54eLFi6V3AcrZ+PHjIZFIcP78efTr1w/u7u6oW7cugoKCcPbs2Tceu2bNGtStWxdSqRT29vbw9/d/bd+pU6fC3d0dxsbGcHFxwYwZM5CTk6Nqf9N1ffjwIXx9fVGlShXIZDLUrVsX+/btK50LoCH+++/i5bZs2TJ4enpCJpPB0dER48ePR1pamuqYV4dpSLvx2TQabsuWLfDw8ICHhwc++OADBAQEYMaMGW98MN/w4cNx5swZLF++HA0aNEB0dDSePn1aaN/MzEx4eXlh6tSpMDU1xd69ezFs2DC4uLigefPmiIuLw+DBg7Fw4UL07t0bqampOHHiBARBgFKpRK9evTBmzBhs3rwZ2dnZOH/+vEY9NPBN0tLSsHHjRri6usLS0vK1/aZNm4bw8HAsWbIEbdq0QVxcHP7+++9C++bl5aFatWrYunUrrKyscPr0aXz00Uewt7fHgAED3npNhw4dikaNGiEsLAy6urqIjIyEvr5+mXz+svbs2TPs378fc+bMgUwmK9D+ph9kYWFhCAoKwvz58+Hj44OUlBScOnXqtf3lcjnWrVsHBwcHXLt2DWPGjIFcLkdwcDCAN1/XCRMmIDs7G3/99RdkMhlu3rwJExOTkn34SkBHRwfLly9HjRo1EB0djfHjxyM4OBjff/+92KFRRSSQRmvVqpWwdOlSQRAEIScnR7CyshIOHTr02v5RUVECgNf2OXr0qABASE5Ofu05unbtKkyePFkQBEGIiIgQAAgPHjwo0C8pKUkAIBw7dqwYn6jiGjFihKCrqyvIZDJBJpMJAAR7e3shIiLitccoFApBKpUK4eHhhbZHR0cLAITLly+/9hzjx48X+vbtKwjC26+pXC4X1q1bV/QPVYGdO3dOACDs2LGj2Mc6ODgI06dPf207AGHnzp2vbV+4cKHg5eWlev2m6+rp6SmEhIQUO8bK4tV/FzKZTOjXr1+Bflu3bhUsLS1Vr9euXSuYmZmpXs+aNUto0KBBOURMFRGHaTRYVFQUzp8/j0GDBgEA9PT0MHDgQKxZs+a1x0RGRkJXVxdt27Yt0nvk5uZizpw5qF+/PiwtLWFiYoKDBw+q5qY0aNAAHTp0gKenJ/r374/w8HAkJycDACwsLDBy5Eh4e3vD19cXy5YtQ1xcXAk/tbjat2+PyMhIREZG4ty5c+jcuTN8fHxeO/R069YtZGVloUOHDkV+j5UrV6JJkyawtraGiYkJwsPDVdf7bdc0KCgIo0ePRseOHTF//nzcu3evZB9YRML/bg5d3EpaQkICHj9+XKxrvm3bNrRp0wZ2dnYwMTHBjBkz1OZfvem6Tpw4EV9//TVat26NWbNmaeWE5v/+u4iMjMTy5ctx9OhRdOrUCVWrVoVcLsfw4cORlJSkGsIl+i8mIxps9erVUCqVqFq1KvT09KCnp4ewsDDs2LFDlRC8ysjIqFjvsWjRIixZsgTBwcE4cuQIIiMj4e3tjezsbACArq4uDh06hD/++AN16tRBaGgoPDw8EB0dDQBYu3Ytzpw5g1atWmHLli1wd3d/61h/RSaTyeDq6gpXV1c0a9YMq1evRnp6OsLDwwvtX9zrvXXrVkyaNAmjRo3CwYMHERkZiQ8//FB1vYE3X9OQkBDcuHED3bp1w5EjR1CnTh3s3Lnz3T+wiNzc3CCRSHDr1q1iHVfca3727FkMGjQIPj4+2LNnDy5fvozp06erXfM3XdfRo0fj/v37GDZsGK5du4YmTZogNDS0WDFouv/+u3B1dUV2dja6du2KevXqYfv27YiIiMB3330HAGpzcYhUxC7N0LvJyckRbG1thUWLFgnXrl1T29zd3YXQ0NBCj4uOjhYkEkmRh2m6d+8ujBo1StWem5sruLu7Cz179iz0eKVSKVStWlVYtGhRoe0tWrQQAgICiv5BK5ARI0YU+Ny5ubmCXC4XgoKCCj0mIyNDMDIyKvIwjb+/v/D++++r9enQocMby9dvuqaDBg0SfH19X3tsRdelSxehatWqQlpaWoG2Nw0l1qhRo8jDNN9++63g4uKi1u7n56c2hPCqN13Xzz77TPD09HztsZVNYf8utm3bJujp6Qm5ubmqfV999ZXadwuHaei/WBnRUHv27EFycjL8/PxQr149ta1fv36vXR1To0YNjBgxAqNGjcKuXbsQHR2NY8eOYevWrYX2d3V1xaFDh3D69GncunULH3/8MeLj41Xt586dw9y5c3Hx4kU8evQIO3bsQGJiImrXro3o6GhMmzYNZ86cwcOHD3Hw4EHcvn0btWvXLpNrUh6ysrIQHx+P+Ph43Lp1CwEBAUhLS4Ovr2+h/Q0NDTF16lQEBwfjp59+wr1793D27NnX/v/j6uqKixcv4sCBA7h9+zZmzJiBCxcuqNrfdE0zMjLg7++PY8eO4eHDhzh16hQuXLig0df7+++/R25uLpo1a4bt27fjzp07uHXrFpYvX46WLVu+9riQkBAsWrQIy5cvx507d3Dp0qXXVitcXV3x6NEj/PLLL7h37x6WL1+uVk1623UNDAzEgQMHEB0djUuXLuHIkSMafc1LQ82aNaFUKhEaGor79+9jw4YNWLlypdhhUUUmdjZE76Z79+5C165dC217Oan0dRMrMzIyhEmTJgn29vaCgYGB4OrqKqxZs0YQhIKVkaSkJKFnz56CiYmJYGNjI3zxxRfC8OHDVb8J3bx5U/D29hasra0FqVSqVpWJj48XevXqpXofJycnYebMmWq/LWmSESNGCABUm1wuF5o2bSps27btjcfl5uYKX3/9teDk5CTo6+sL1atXF+bOnSsIQsHKSGZmpjBy5EjBzMxMMDc3F8aNGyd89tlnqt8Y33RNs7KyhEGDBgmOjo6CgYGB4ODgIPj7+wsZGRlleVnK3OPHj4UJEyYITk5OgoGBgVC1alWhR48ewtGjR9943MqVKwUPDw9BX19fsLe3V6se4ZUJrJ9++qlgaWkpmJiYCAMHDhSWLFmi+q39bdfV399fqFmzpiCVSgVra2th2LBhwtOnT0v7MlRYhVVGBEEQFi9eLNjb2wtGRkaCt7e38NNPP7EyQq8lEYT/zRIjIiIiEgGHaYiIiEhUTEaIiIhIVExGiIiISFRMRoiIiEhUTEaIiIhIVExGiIiISFRMRoiIiEhUTEaIiIhIVExGiCq5kJAQNGzYUPV65MiR6NWrV7nH8eDBA0gkEkRGRr62T40aNbB06dIin3PdunUwNzcvcWwSiQS7du0q8XmI6N0wGSESwciRIyGRSCCRSKCvrw8XFxdMmTKlXB6vvmzZMqxbt65IfYuSQBARlZSe2AEQaasuXbpg7dq1yMnJwYkTJzB69Gikp6cjLCysQN+cnBzo6+uXyvuamZmVynmIiEoLKyNEIpFKpbCzs4OjoyOGDBmCoUOHqoYKXg6trFmzBi4uLpBKpRAEASkpKfjoo49gY2MDU1NTvP/++7hy5YraeefPnw9bW1vI5XL4+fkhMzNTrf3VYZq8vDwsWLAArq6ukEqlqF69OubMmQMAcHZ2BgA0atQIEokE7dq1Ux23du1a1K5dG4aGhqhVqxa+//57tfc5f/48GjVqBENDQzRp0gSXL18u9jVavHgxPD09IZPJ4OjoiPHjxyMtLa1Av127dsHd3R2Ghobo1KkTYmJi1Np///13eHl5wdDQEC4uLpg9ezaUSmWx4yGissFkhKiCMDIyQk5Ojur13bt3sXXrVmzfvl01TNKtWzfEx8dj3759iIiIQOPGjdGhQwc8e/YMALB161bMmjULc+bMwcWLF2Fvb18gSXjVtGnTsGDBAsyYMQM3b97Epk2bYGtrCyA/oQCAP//8E3FxcdixYwcAIDw8HNOnT8ecOXNw69YtzJ07FzNmzMD69esBAOnp6ejevTs8PDwQERGBkJAQTJkypdjXREdHB8uXL8f169exfv16HDlyBMHBwWp9Xrx4gTlz5mD9+vU4deoUFAoFBg0apGo/cOAAPvjgA0ycOBE3b97EqlWrsG7dOlXCRUQVgMhPDSbSSq8+dv3cuXOCpaWlMGDAAEEQ8h+nrq+vLyQkJKj6HD58WDA1NRUyMzPVzlWzZk1h1apVgiAIQsuWLYWxY8eqtTdv3lzt0ez/fW+FQiFIpVIhPDy80Dijo6MFAMLly5fV9js6OgqbNm1S2/fVV18JLVu2FARBEFatWiVYWFgI6enpqvawsLBCz/VfTk5OwpIlS17bvnXrVsHS0lL1eu3atQIA4ezZs6p9t27dEgAI586dEwRBEP7v//5PmDt3rtp5NmzYINjb26teAxB27tz52vclorLFOSNEItmzZw9MTEygVCqRk5ODnj17IjQ0VNXu5OQEa2tr1euIiAikpaXB0tJS7TwZGRm4d+8eAODWrVsYO3asWnvLli1x9OjRQmO4desWsrKy0KFDhyLHnZiYiJiYGPj5+WHMmDGq/UqlUjUf5datW2jQoAGMjY3V4iiuo0ePYu7cubh58yYUCgWUSiUyMzORnp4OmUwGANDT00OTJk1Ux9SqVQvm5ua4desWmjVrhoiICFy4cEGtEpKbm4vMzEy8ePFCLUYiEgeTESKRtG/fHmFhYdDX14eDg0OBCaovf9i+lJeXB3t7exw7dqzAud51eauRkVGxj8nLywOQP1TTvHlztTZdXV0AgCAI7xTPfz18+BBdu3bF2LFj8dVXX8HCwgInT56En5+f2nAWkL8091Uv9+Xl5WH27Nno06dPgT6GhoYljpOISo7JCJFIZDIZXF1di9y/cePGiI+Ph56eHmrUqFFon9q1a+Ps2bMYPny4at/Zs2dfe043NzcYGRnh8OHDGD16dIF2AwMDAPmVhJdsbW1RtWpV3L9/H0OHDi30vHXq1MGGDRuQkZGhSnjeFEdhLl68CKVSiUWLFkFHJ39629atWwv0UyqVuHjxIpo1awYAiIqKwvPnz1GrVi0A+dctKiqqWNeaiMoXkxEiDdGxY0e0bNkSvXr1woIFC+Dh4YHHjx9j37596NWrF5o0aYJPPvkEI0aMQJMmTdCmTRts3LgRN27cgIuLS6HnNDQ0xNSpUxEcHAwDAwO0bt0aiYmJuHHjBvz8/GBjYwMjIyPs378f1apVg6GhIczMzBASEoKJEyfC1NQUPj4+yMrKwsWLF5GcnIygoCAMGTIE06dPh5+fH7744gs8ePAA3377bbE+b82aNaFUKhEaGgpfX1+cOnUKK1euLNBPX18fAQEBWL58OfT19eHv748WLVqokpOZM2eie/fucHR0RP/+/aGjo4OrV6/i2rVr+Prrr4v/fwQRlTqupiHSEBKJBPv27cN7772HUaNGwd3dHYMGDcKDBw9Uq18GDhyImTNnYurUqfDy8sLDhw8xbty4N553xowZmDx5MmbOnInatWtj4MCBSEhIAJA/H2P58uVYtWoVHBwc0LNnTwDA6NGj8eOPP2LdunXw9PRE27ZtsW7dOtVSYBMTE/z++++4efMmGjVqhOnTp2PBggXF+rwNGzbE4sWLsWDBAtSrVw8bN27EvHnzCvQzNjbG1KlTMWTIELRs2RJGRkb45ZdfVO3e3t7Ys2cPDh06hKZNm6JFixZYvHgxnJycihUPEZUdiVAag7tERERE74iVESIiIhIVkxEiIiISFZMRIiIiEhWTESIiIhIVkxEiIiISFZMRIiIiEhWTESIiIhIVkxEiIiISFZMRIiIiEhWTESIiIhIVkxEiIiIS1f8DutbmZMipJeMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('multiclass_mlp_3l.h5')\n",
    "\n",
    "loss, accuracy = model.evaluate(X_dev, y_dev, batch_size=32)\n",
    "print(f\"Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Predict class probabilities\n",
    "y_pred_probs = model.predict(X_dev)\n",
    "\n",
    "# Convert probabilities to predicted class labels (choose the class with highest probability)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Convert one-hot encoded y_dev to class labels for comparison\n",
    "y_dev_labels = np.argmax(y_dev, axis=1)\n",
    "\n",
    "# Print classification report for multi-class classification\n",
    "print(classification_report(y_dev_labels, y_pred, target_names=[\"A class\", \"B class\", \"C class\", \"Fail\"]))\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_dev_labels, y_pred)\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=[\"A class\", \"B class\", \"C class\", \"Fail\"])\n",
    "disp.plot(cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
